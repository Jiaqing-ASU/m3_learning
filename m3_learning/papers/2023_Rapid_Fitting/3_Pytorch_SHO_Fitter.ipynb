{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SHO Fitting in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "sys.path.append('/home/ferroelectric/m3_learning/m3_learning/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from m3_learning.nn.random import random_seed\n",
    "from m3_learning.viz.style import set_style\n",
    "from m3_learning.viz.printing import printer\n",
    "from m3_learning.be.viz import Viz\n",
    "from m3_learning.be.dataset import BE_Dataset\n",
    "# from m3_learning.be.nn import SHO_Model, SHO_NN_Model, SHO_fit_func_nn\n",
    "\n",
    "# from m3_learning.be.dataset import BE_Dataset\n",
    "printing = printer(basepath = './../../../Figures/2023_rapid_fitting/')\n",
    "\n",
    "\n",
    "set_style(\"printing\")\n",
    "random_seed(seed=42)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# from scipy.signal import resample\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# from m3_learning.optimizers.AdaHessian import AdaHessian\n",
    "# from m3_learning.nn.SHO_fitter.SHO import SHO_fit_func_torch\n",
    "# from m3_learning.be.processing import convert_amp_phase, SHO_fit_to_array\n",
    "# from m3_learning.util.preprocessing import global_scaler\n",
    "# from m3_learning.nn.random import random_seed\n",
    "# from m3_learning.nn.benchmarks.inference import computeTime\n",
    "from m3_learning.util.file_IO import make_folder\n",
    "from m3_learning.be.nn import SHO_fit_func_nn, SHO_Model\n",
    "# from m3_learning.be.dataset import BE_Dataset\n",
    "# from m3_learning.viz.style import set_style\n",
    "\n",
    "# set_style(\"printing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# # sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# # Load the example tips dataset\n",
    "# tips = sns.load_dataset(\"tips\")\n",
    "\n",
    "# # Draw a nested violinplot and split the violins for easier comparison\n",
    "# sns.violinplot(data=tips, x=\"day\", y=\"total_bill\", hue=\"smoker\",\n",
    "#                split=True, inner=\"quart\", linewidth=1,\n",
    "#                palette={\"Yes\": \"b\", \"No\": \".85\"})\n",
    "# sns.despine(left=True)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename and the path to save the file\n",
    "filename = 'data_raw.h5'\n",
    "save_path = './../../../Data/2023_rapid_fitting'\n",
    "\n",
    "\n",
    "data_path = save_path + '/' + filename\n",
    "\n",
    "# instantiate the dataset object\n",
    "dataset = BE_Dataset(data_path, resample_bins = 80,  SHO_fit_func_NN = SHO_fit_func_nn)\n",
    "\n",
    "# print the contents of the file\n",
    "dataset.print_be_tree()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Torch Function\n",
    "\n",
    "The function for a simple-harmonic oscillator needs to be recast in PyTorch. Here we prove that the PyTorch function is implemented identically to the Numpy model. \n",
    "\n",
    "Note: This uses the results from the least squares fitting LSQF results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = {'fitter' : 'NN',\n",
    "        'resampled' : False, \n",
    "        \"label\": \"NN Fit\"}\n",
    "\n",
    "predicted = {'fitter' : 'LSQF',\n",
    "             'resampled' : False, \n",
    "             \"label\": \"Raw\", \n",
    "             'scaled': False}\n",
    "\n",
    "BE_viz = Viz(dataset, printing, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BE_viz.fit_tester(true, predicted, filename=\"Figure_7_PyTorch_fit_tester\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 7** Shows the result of the PyTorch function. The result based on the LSQF results shows that the PyTorch function is implemented correctly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Model\n",
    "\n",
    "### Model Architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the Data\n",
    "\n",
    "When training the neural network it is useful to scale the data. We apply a global scaler such that the spectrum have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "#### Visualizing the Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BE_viz = Viz(dataset, printing, verbose=True)\n",
    "\n",
    "\n",
    "state = {'fitter' : 'LSQF',\n",
    "             'resampled' : True,\n",
    "             'scaled' : True,\n",
    "             \"label\": \"Scaled\"}\n",
    "\n",
    "BE_viz.nn_checker(state, filename=\"Figure_8_Scaled Raw Data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 8** shows the scaled data. The data is scaled to have a mean of 0 and a standard deviation of 1. This is done using a global scaler of the entire spectrum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.LSQF_phase_shift = np.pi/2\n",
    "\n",
    "BE_viz.SHO_hist(dataset.SHO_fit_results(),\n",
    "                      filename=\"Figure_9_Phase_Shifted_Scaled_Histograms\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 9** shows the histograms of the scaled a) amplitude, b) resonance frequency, c) quality factor, and d) phase. Note there is a transformation applied to the phase.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "We will train the model from scratch. Generally the model trains very well in a few epochs. This will take less than 5 minutes to train on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed(seed=42)\n",
    "\n",
    "# instantiate the model\n",
    "model = SHO_Model(dataset, training=True, model_basename='SHO_Fitter_original_data')\n",
    "\n",
    "# constructs a test train split\n",
    "X_train, X_test, y_train, y_test = dataset.test_train_split_(shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = False\n",
    "\n",
    "if train:\n",
    "    # fits the model\n",
    "    model.fit(dataset.X_train, 200, loss_func=CustomLoss(penalty=2, verbose=False, scale_factor=dataset.SHO_scaler.mean_[0]))\n",
    "else:\n",
    "    model.load(\"/home/ferroelectric/m3_learning/m3_learning/papers/2023_Rapid_Fitting/Trained Models/SHO Fitter/SHO_Fitter_original_data_model_epoch_5_train_loss_0.0414678600463958.pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Inference Speedtest\n",
    "\n",
    "Here we show the speedtest for the GPU. This is done using the torch.cuda.synchronize() function. This is used to ensure that the GPU is done processing before the timer is stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, Y_data = dataset.NN_data()\n",
    "\n",
    "model.inference_timer(X_data, batch_size=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the Distribution of the NN Fit Results\n",
    "\n",
    "It is useful to check the distribution of the scaled and unscaled fit results for the entire dataset, this will also allow us to add a correction for a phase shift (if necessary)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unscaled Histograms of Neural Network Fit Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.NN_phase_shift = -3*np.pi/2\n",
    "\n",
    "pred_data, scaled_param, parm = model.predict(X_train)\n",
    "\n",
    "BE_viz.SHO_hist(parm, filename = \"Figure_10_NN_Unscaled_Histograms\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 10** Calculated fitting parameters from the neural network.  Histograms of the unscaled a) amplitude, b) resonance frequency, c) quality factor, and d) phase. Note there is a transformation applied to the phase.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaled Histograms of Neural Network Fit Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BE_viz.SHO_hist(scaled_param, filename = \"Figure_11_NN_Scaled_Histograms\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 11** Calculated fitting parameters from the neural network.  Histograms of the scaled a) amplitude, b) resonance frequency, c) quality factor, and d) phase. Note there is a transformation applied to the phase.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation\n",
    "\n",
    "It is helpful to view reconstructions of the data from the training and validation datasets. This ensures that the model is doing a good job of fitting the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Training Data Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BE_viz.nn_validation(model, X_train, \n",
    "                     filename = \"Figure_11_NN_Validation_example_training\", \n",
    "                     SHO_results = y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 11** A random reconstruction of the neural network fits for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BE_viz.nn_validation(model, X_test, \n",
    "                     filename = \"Figure_12_NN_Validation_example_test\", \n",
    "                     SHO_results = y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 12** A random reconstruction of the neural network fits for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"raw_format\": \"magnitude spectrum\",}\n",
    "\n",
    "BE_viz.set_attributes(**state)\n",
    "\n",
    "BE_viz.best_median_worst_reconstructions(model, X_data, SHO_values=Y_data, filename=\"Figure_13_NN_Best_Median_Worst_Reconstructions_Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BE_viz.best_median_worst_reconstructions(model, X_test, SHO_values=y_test, filename=\"Figure 14_NN_Best_Median_Worst_Reconstructions_Testing\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the fit results are excellent for both the training and validation datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of NN and LSQF Results\n",
    "\n",
    "It is useful to compare the NN and LSQF results. While generally, the LSQF results might be considered the ground truth, this is not really the case. It is unclear which fitting method is actually more precise and accurate. We conjecture through this analysis that the neural network is actually a more accurate and precise fitting method. \n",
    "\n",
    "This section will help to make this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {'fitter' : 'LSQF',\n",
    "             'resampled' : True,\n",
    "             'scaled' : False, \n",
    "             \"raw_format\": \"magnitude spectrum\",}\n",
    "\n",
    "BE_viz.set_attributes(**state)\n",
    "\n",
    "LSQF_results = dataset.raw_spectra(fit_results = dataset.SHO_fit_results())\n",
    "\n",
    "state = {'fitter' : 'LSQF',\n",
    "             'resampled' : True,\n",
    "             'scaled' : False, \n",
    "             \"raw_format\": \"magnitude spectrum\",}\n",
    "\n",
    "BE_viz.set_attributes(**state)\n",
    "\n",
    "raw_spectra = dataset.raw_spectra()\n",
    "\n",
    "# ind, mse = BE_viz.best_median_worst_fit_comparison(LSQF_results, raw_spectra, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BE_viz.best_median_worst_fit_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = BE_viz\n",
    "\n",
    "# for the SHO curves it makes sense to determine the error based on the normalized fit results in complex form. \n",
    "state = {'fitter' : 'LSQF',\n",
    "        'resampled' : False,\n",
    "        'scaled' : True, \n",
    "        \"raw_format\": \"complex\",}\n",
    "\n",
    "self.set_attributes(**state)\n",
    "\n",
    "fit_results_compare = self.dataset.raw_spectra(fit_results = self.dataset.SHO_fit_results())\n",
    "\n",
    "raw_SHO = self.dataset.raw_spectra()\n",
    "\n",
    "index1, mse1, d1, d2 = SHO_Model.get_rankings(raw_SHO, fit_results_compare, n = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = raw_SHO[0].reshape(-1, 165)[745386]\n",
    "b = np.array(fit_results_compare[0].reshape(-1, 165)[745386])\n",
    "\n",
    "a1 = raw_SHO[1].reshape(-1, 165)[745386]\n",
    "b1 = np.array(fit_results_compare[1].reshape(-1, 165)[745386])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.mean((a-b)**2) + np.mean((a1-b1)**2))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.resampled_freq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataset.frequency_bin)\n",
    "plt.plot(dataset.resampled_freq, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(\n",
    "    X_data[745386,:,0])\n",
    "# plt.plot(dataset.frequency_bin, a)\n",
    "# plt.plot(dataset.frequency_bin, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {'fitter' : 'LSQF',\n",
    "             'resampled' : True,\n",
    "             'scaled' : True, \n",
    "             \"raw_format\": \"complex\",}\n",
    "\n",
    "BE_viz.set_attributes(**state)\n",
    "\n",
    "LSQF_results = dataset.raw_spectra(fit_results = dataset.SHO_fit_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(d1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d1[0][0])\n",
    "plt.plot(d1[1][0])\n",
    "mse1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(LSQF_results).shape.index(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(LSQF_results).shape.index(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index, mse, c1, c2 = SHO_Model.get_rankings(LSQF_results, raw_spectra, n= 1, curves=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(c1[0,0])\n",
    "plt.plot(c2[0,0] , 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(c1[2,:,1])\n",
    "plt.plot(c2[2,:,1] , 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[tensor.numpy() for tensor in LSQF_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(LSQF_results[0][100,100,:])\n",
    "plt.plot(raw_spectra[0][100,100,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0### LSQF NN compairison resonstruction\n",
    "\n",
    "### LSQF NN comapairison distributions\n",
    "\n",
    "### LSQF NN comparison movies.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "true = params_test\n",
    "compare = dataset.nn_validation_params_scaled\n",
    "\n",
    "names = [true, compare]\n",
    "names_str = ['SHO', 'NN']\n",
    "labels = ['Amplitude', 'Resonance', 'Q-Factor', 'Phase']\n",
    "\n",
    "for j, name in enumerate(names):\n",
    "    for i, label in enumerate(labels):\n",
    "        dict_ = {\"value\": name[:,i],\n",
    "                 \"parameter\": np.repeat(label, name.shape[0]),\n",
    "                 \"dataset\": np.repeat(names_str[j], name.shape[0])}\n",
    "        \n",
    "        df = pd.concat((df, pd.DataFrame(dict_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df.head()\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(10, 10), sharey=True)\n",
    "\n",
    "sns.violinplot(x='parameter', y='value', hue='dataset',\n",
    "               data=df, ax=axs, scale='count', split=True, inner='quartile')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapidfitting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b88dbc8072abb6ef9a30839cda5b7a1baf9f1401fa4b52ed02da9e59e44435e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
