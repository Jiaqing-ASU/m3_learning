{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHO Fitter on the noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"/home/ferroelectric/m3_learning/m3_learning/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from m3_learning.be.dataset import BE_Dataset\n",
    "from m3_learning.viz.printing import printer\n",
    "from m3_learning.be.nn import SHO_fit_func_nn, SHO_Model\n",
    "\n",
    "\n",
    "# from m3_learning.be.dataset import BE_Dataset\n",
    "printing = printer(basepath = './../../../Figures/2023_rapid_fitting/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('../../')\n",
    "# sys.path.append('/home/ferroelectric/m3_learning/m3_learning/src')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import h5py\n",
    "# import time\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import shutil\n",
    "# import gc\n",
    "# import gdown\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# from scipy.signal import resample\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import train_test_split \n",
    "\n",
    "# from src.m3_learning.optimizers.AdaHessian import AdaHessian\n",
    "# from src.m3_learning.nn.SHO_fitter.SHO import SHO_fit_func_torch\n",
    "# from src.m3_learning.be.processing import convert_amp_phase, SHO_Fitter, SHO_fit_to_array\n",
    "# from src.m3_learning.nn.random import random_seed\n",
    "# from src.m3_learning.util.preprocessing import global_scaler\n",
    "# from src.m3_learning.viz.layout import layout_fig\n",
    "\n",
    "# from src.m3_learning.be.util import print_be_tree\n",
    "\n",
    "# from src.m3_learning.viz.printing import printer\n",
    "# from src.m3_learning.viz.layout import combine_lines, labelfigs\n",
    "\n",
    "\n",
    "# printing = printer(basepath='./figures/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdown.download(\n",
    "#     \"https://drive.google.com/uc?export=download&id=1Q2Qo_1VGlCsVOTjQpZlE5tjoIV1etVe2\",\n",
    "#     path + \"data_file_google.h5\",\n",
    "#     quiet=False,\n",
    "#     resume=True,\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sets path to file\n",
    "# path = r\"./\"\n",
    "\n",
    "# # Opens the data file\n",
    "# h5_f = h5py.File(path + \"data_file.h5\", \"r+\")\n",
    "\n",
    "# # number of pixels in the image\n",
    "# num_pix = h5_f[\"Measurement_000\"].attrs[\"num_pix\"]\n",
    "\n",
    "# num_pix_1d = int(np.sqrt(num_pix))\n",
    "\n",
    "# # Frequency Vector in Hz\n",
    "# frequency_bin = h5_f[\"Measurement_000\"][\"Channel_000\"][\"Bin_Frequencies\"][:]\n",
    "\n",
    "# # extracting spectroscopic values\n",
    "# spectroscopic_values = h5_f['Measurement_000']['Channel_000']['Spectroscopic_Values']\n",
    "\n",
    "# # number of DC voltage steps\n",
    "# voltage_steps = h5_f[\"Measurement_000\"].attrs[\"num_udvs_steps\"]\n",
    "\n",
    "# # Resampled frequency vector\n",
    "# wvec_freq = resample(frequency_bin, 80)\n",
    "\n",
    "# # get raw data (real and imaginary combined)\n",
    "# raw_data = h5_f[\"Measurement_000\"][\"Channel_000\"][\"Raw_Data\"]\n",
    "# raw_data_resampled = resample(np.array(h5_f[\"Measurement_000\"][\"Channel_000\"][\"Raw_Data\"]).reshape(-1, 165), 80, axis=1)\n",
    "\n",
    "# # conversion of raw data (both resampled and full)\n",
    "# amp, phase = convert_amp_phase(raw_data)\n",
    "# amp_resample, phase_resample = convert_amp_phase(raw_data_resampled)\n",
    "\n",
    "# scaled_data = h5_f[\"Measurement_000\"][\"Channel_000\"]['complex']['scaled_data'][:]\n",
    "# real_resample = h5_f[\"Measurement_000\"][\"Channel_000\"]['complex']['real_resample'][:]\n",
    "# imag_resample = h5_f[\"Measurement_000\"][\"Channel_000\"]['complex']['imag_resample'][:]\n",
    "\n",
    "# # scale the real component of input data\n",
    "# scaler_real = global_scaler()\n",
    "# scaled_data_real = scaler_real.fit_transform(real_resample).reshape(-1, 80)\n",
    "\n",
    "# # scale the imaginary component of input data\n",
    "# scaler_imag = global_scaler()\n",
    "# scaled_data_imag = scaler_imag.fit_transform(imag_resample).reshape(-1, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "├ Measurement_000\n",
      "  ---------------\n",
      "  ├ Channel_000\n",
      "    -----------\n",
      "    ├ Bin_FFT\n",
      "    ├ Bin_Frequencies\n",
      "    ├ Bin_Indices\n",
      "    ├ Bin_Step\n",
      "    ├ Bin_Wfm_Type\n",
      "    ├ Excitation_Waveform\n",
      "    ├ Noise_Floor\n",
      "    ├ Position_Indices\n",
      "    ├ Position_Values\n",
      "    ├ Raw_Data\n",
      "    ├ Raw_Data_Reshaped\n",
      "    ├ Spatially_Averaged_Plot_Group_000\n",
      "      ---------------------------------\n",
      "      ├ Bin_Frequencies\n",
      "      ├ Max_Response\n",
      "      ├ Mean_Spectrogram\n",
      "      ├ Min_Response\n",
      "      ├ Spectroscopic_Parameter\n",
      "      ├ Step_Averaged_Response\n",
      "    ├ Spatially_Averaged_Plot_Group_001\n",
      "      ---------------------------------\n",
      "      ├ Bin_Frequencies\n",
      "      ├ Max_Response\n",
      "      ├ Mean_Spectrogram\n",
      "      ├ Min_Response\n",
      "      ├ Spectroscopic_Parameter\n",
      "      ├ Step_Averaged_Response\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n",
      "    ├ UDVS\n",
      "    ├ UDVS_Indices\n",
      "    ├ original_data_2STD\n",
      "    ├ raw_data_resampled\n",
      "├ Raw_Data-SHO_Fit_000\n",
      "  --------------------\n",
      "  ├ Fit\n",
      "  ├ Guess\n",
      "  ├ SHO_LSQF\n",
      "  ├ Spectroscopic_Indices\n",
      "  ├ Spectroscopic_Values\n",
      "  ├ completed_fit_positions\n",
      "  ├ completed_guess_positions\n",
      "Datasets and datagroups within the file:\n",
      "------------------------------------\n",
      "/\n",
      "/Measurement_000\n",
      "/Measurement_000/Channel_000\n",
      "/Measurement_000/Channel_000/Bin_FFT\n",
      "/Measurement_000/Channel_000/Bin_Frequencies\n",
      "/Measurement_000/Channel_000/Bin_Indices\n",
      "/Measurement_000/Channel_000/Bin_Step\n",
      "/Measurement_000/Channel_000/Bin_Wfm_Type\n",
      "/Measurement_000/Channel_000/Excitation_Waveform\n",
      "/Measurement_000/Channel_000/Noise_Floor\n",
      "/Measurement_000/Channel_000/Position_Indices\n",
      "/Measurement_000/Channel_000/Position_Values\n",
      "/Measurement_000/Channel_000/Raw_Data\n",
      "/Measurement_000/Channel_000/Raw_Data_Reshaped\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000/Bin_Frequencies\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000/Max_Response\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000/Mean_Spectrogram\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000/Min_Response\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000/Spectroscopic_Parameter\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000/Step_Averaged_Response\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001/Bin_Frequencies\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001/Max_Response\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001/Mean_Spectrogram\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001/Min_Response\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001/Spectroscopic_Parameter\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001/Step_Averaged_Response\n",
      "/Measurement_000/Channel_000/Spectroscopic_Indices\n",
      "/Measurement_000/Channel_000/Spectroscopic_Values\n",
      "/Measurement_000/Channel_000/UDVS\n",
      "/Measurement_000/Channel_000/UDVS_Indices\n",
      "/Measurement_000/Channel_000/original_data_2STD\n",
      "/Measurement_000/Channel_000/raw_data_resampled\n",
      "/Raw_Data-SHO_Fit_000\n",
      "/Raw_Data-SHO_Fit_000/Fit\n",
      "/Raw_Data-SHO_Fit_000/Guess\n",
      "/Raw_Data-SHO_Fit_000/SHO_LSQF\n",
      "/Raw_Data-SHO_Fit_000/Spectroscopic_Indices\n",
      "/Raw_Data-SHO_Fit_000/Spectroscopic_Values\n",
      "/Raw_Data-SHO_Fit_000/completed_fit_positions\n",
      "/Raw_Data-SHO_Fit_000/completed_guess_positions\n",
      "\n",
      "The main dataset:\n",
      "------------------------------------\n",
      "<HDF5 file \"data_raw copy.h5\" (mode r+)>\n",
      "\n",
      "The ancillary datasets:\n",
      "------------------------------------\n",
      "<HDF5 dataset \"Position_Indices\": shape (3600, 2), type \"<u4\">\n",
      "<HDF5 dataset \"Position_Values\": shape (3600, 2), type \"<f4\">\n",
      "<HDF5 dataset \"Spectroscopic_Indices\": shape (4, 63360), type \"<u4\">\n",
      "<HDF5 dataset \"Spectroscopic_Values\": shape (4, 63360), type \"<f4\">\n",
      "\n",
      "Metadata or attributes in a datagroup\n",
      "------------------------------------\n",
      "BE_actual_duration_[s] : 0.004\n",
      "BE_amplitude_[V] : 1\n",
      "BE_auto_smoothing : auto smoothing on\n",
      "BE_band_edge_smoothing_[s] : 4832.1\n",
      "BE_band_edge_trim : 0.094742\n",
      "BE_band_width_[Hz] : 200000\n",
      "BE_bins_per_band : 0\n",
      "BE_center_frequency_[Hz] : 1310000\n",
      "BE_desired_duration_[s] : 0.004\n",
      "BE_phase_content : chirp-sinc hybrid\n",
      "BE_phase_variation : 1\n",
      "BE_points_per_BE_wave : 0\n",
      "BE_repeats : 4\n",
      "FORC_V_high1_[V] : 1\n",
      "FORC_V_high2_[V] : 10\n",
      "FORC_V_low1_[V] : -1\n",
      "FORC_V_low2_[V] : -10\n",
      "FORC_num_of_FORC_cycles : 1\n",
      "FORC_num_of_FORC_repeats : 1\n",
      "File_MDAQ_version : MDAQ_VS_090915_01\n",
      "File_date_and_time : 18-Sep-2015 18:32:14\n",
      "File_file_name : SP128_NSO\n",
      "File_file_path : C:\\Users\\Asylum User\\Documents\\Users\\Agar\\SP128_NSO\\\n",
      "File_file_suffix : 99\n",
      "IO_AO_amplifier : 10\n",
      "IO_AO_range_[V] : +/- 10\n",
      "IO_Analog_Input_1 : +/- .1V, FFT\n",
      "IO_Analog_Input_2 : off\n",
      "IO_Analog_Input_3 : off\n",
      "IO_Analog_Input_4 : off\n",
      "IO_DAQ_platform : NI 6115\n",
      "IO_rate_[Hz] : 4000000\n",
      "VS_amplitude_[V] : 16\n",
      "VS_cycle_fraction : full\n",
      "VS_cycle_phase_shift : 0\n",
      "VS_measure_in_field_loops : in and out-of-field\n",
      "VS_mode : DC modulation mode\n",
      "VS_number_of_cycles : 2\n",
      "VS_offset_[V] : 0\n",
      "VS_read_voltage_[V] : 0\n",
      "VS_set_pulse_amplitude[V] : 0\n",
      "VS_set_pulse_duration[s] : 0.002\n",
      "VS_step_edge_smoothing_[s] : 0.001\n",
      "VS_steps_per_full_cycle : 96\n",
      "data_type : BEPSData\n",
      "grid_/single : grid\n",
      "grid_contact_set_point_[V] : 1\n",
      "grid_current_col : 1\n",
      "grid_current_row : 1\n",
      "grid_cycle_time_[s] : 10\n",
      "grid_measuring : 0\n",
      "grid_moving : 0\n",
      "grid_num_cols : 60\n",
      "grid_num_rows : 60\n",
      "grid_settle_time_[s] : 0.15\n",
      "grid_time_remaining_[h;m;s] : 10\n",
      "grid_total_time_[h;m;s] : 10\n",
      "grid_transit_set_point_[V] : 0.1\n",
      "grid_transit_time_[s] : 0.15\n",
      "num_bins : 165\n",
      "num_pix : 3600\n",
      "num_udvs_steps : 384\n"
     ]
    }
   ],
   "source": [
    "# Specify the filename and the path to save the file\n",
    "filename = \"data_raw copy.h5\"\n",
    "save_path = \"./../../../Data/2023_rapid_fitting\"\n",
    "\n",
    "\n",
    "data_path = save_path + \"/\" + filename\n",
    "\n",
    "# instantiate the dataset object\n",
    "dataset = BE_Dataset(data_path, resample_bins=80, SHO_fit_func_NN=SHO_fit_func_nn)\n",
    "\n",
    "# print the contents of the file\n",
    "dataset.print_be_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a list for parameters\n",
    "# fit_results_list = SHO_fit_to_array(h5_f[\"Measurement_000\"][\"Channel_000\"][\"Raw_Data-SHO_Fit_000\"][\"Fit\"])\n",
    "\n",
    "# # flatten parameters list into numpy array\n",
    "# fit_results_list = np.array(fit_results_list).reshape(num_pix, voltage_steps, 5)\n",
    "\n",
    "# # exclude the R2 parameter\n",
    "# params = fit_results_list.reshape(-1, 5)[:, 0:4]\n",
    "\n",
    "# # scale the parameters (now takes only 4 parameters, excluding the R2)\n",
    "# params_scaler = StandardScaler()\n",
    "# scaled_params = params_scaler.fit_transform(fit_results_list.reshape(-1, 5)[:, 0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600, 63360)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.original_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0038833667"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(dataset.original_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = dataset\n",
    "\n",
    "def generate_noisy_data(self, noise_multipliers = 2, noise_STD = None):\n",
    "    \n",
    "    if noise_STD is None:\n",
    "        noise_STD = np.std(self.original_data)\n",
    "        \n",
    "    noise_level = noise_STD * noise_multipliers\n",
    "    \n",
    "    noise_real = np.random.uniform(-1*noise_level , noise_level, (3600, 63360))\n",
    "    noise_imag = np.random.uniform(-1*noise_level, noise_level, (3600, 63360))\n",
    "    noise = noise_real+noise_imag*1.0j  \n",
    "    return self.original_data + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = generate_noisy_data(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.data_writer(\"Measurement_000/Channel_000\", \"original_data_2STD\",out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowest_noise_real = -1.0 * 0.0026878386 # 2.6e-3\n",
    "# highest_noise_real = 1.0 * 0.0026878386\n",
    "# lowest_noise_imag = -1.0 * 0.0027575183\n",
    "# highest_noise_imag = 1.0 * 0.0027575183\n",
    "\n",
    "# noise_real = np.random.uniform(lowest_noise_real, highest_noise_real, (3600, 63360))\n",
    "# noise_imag = np.random.uniform(lowest_noise_imag, highest_noise_imag, (3600, 63360))\n",
    "# noise = noise_real+noise_imag*1.0j\n",
    "\n",
    "# noise_levels = ['2.0', '4.0', '7.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all computations were pre-computed on A100 40GB NHI GPU\n",
    "# set to False if you want to recompute\n",
    "use_pre_computed_vars = False\n",
    "use_pre_trained_models = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_be_tree('./data_file_noise_7.0.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copies initial dataset for the later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_pre_computed_vars:\n",
    "  # close the current file to perform a copy\n",
    "  h5_f.close()\n",
    "  for nl in noise_levels:\n",
    "    shutil.copy('data_file_raw.h5', f'data_file_noise_{nl}.h5')\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise_level in noise_levels:\n",
    "  \n",
    "  with h5py.File(f'data_file_noise_{noise_level}.h5', 'r+') as h5_f_noise:\n",
    "    data_pointer = h5_f_noise['Measurement_000']['Channel_000']['Raw_Data']\n",
    "    raw_data_noise = np.array(h5_f_noise['Measurement_000']['Channel_000']['Raw_Data'])\n",
    "    raw_data_noise = raw_data_noise + noise * float(noise_level) \n",
    "    data_pointer[...] = raw_data_noise\n",
    "    del h5_f_noise['Measurement_000']['Channel_000']['Raw_Data-SHO_Fit_000']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Builds the PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHO_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input block of 1d convolution\n",
    "        self.hidden_x1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=2, out_channels=8, kernel_size=7),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=8, out_channels=6, kernel_size=7),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=6, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "        )\n",
    "\n",
    "        # fully connected block\n",
    "        self.hidden_xfc = nn.Sequential(\n",
    "            nn.Linear(256, 20),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.SELU(),\n",
    "        )\n",
    "\n",
    "        # 2nd block of 1d-conv layers\n",
    "        self.hidden_x2 = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=2, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.AvgPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=4, out_channels=2, kernel_size=3),\n",
    "            nn.SELU(),\n",
    "            nn.AvgPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=2, out_channels=2, kernel_size=3),\n",
    "            nn.SELU(),\n",
    "            nn.AvgPool1d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        # Flatten layer\n",
    "        self.flatten_layer = nn.Flatten()\n",
    "\n",
    "        # Final embedding block - Output 4 values - linear\n",
    "        self.hidden_embedding = nn.Sequential(\n",
    "            nn.Linear(26, 16),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(8, 4),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, n=-1):\n",
    "        x = torch.swapaxes(x, 1, 2)  # output shape - samples, (real, imag), frequency\n",
    "        x = self.hidden_x1(x)\n",
    "        xfc = torch.reshape(x, (n, 256))  # batch size, features\n",
    "        xfc = self.hidden_xfc(xfc)\n",
    "        x = torch.reshape(x, (n, 2, 128))  # batch size, (real, imag), timesteps\n",
    "        x = self.hidden_x2(x)\n",
    "        cnn_flat = self.flatten_layer(x)\n",
    "        encoded = torch.cat((cnn_flat, xfc), 1)  # merge dense and 1d conv.\n",
    "        embedding = self.hidden_embedding(encoded)  # output is 4 parameters\n",
    "\n",
    "        # corrects the scaling of the parameters\n",
    "        unscaled_param = (\n",
    "            embedding * torch.tensor(params_scaler.var_[0:4] ** 0.5).cuda()\n",
    "            + torch.tensor(params_scaler.mean_[0:4]).cuda()\n",
    "        )\n",
    "\n",
    "        # passes to the pytorch fitting function\n",
    "        fits = SHO_fit_func_torch(unscaled_param, wvec_freq, device=\"cuda\")\n",
    "\n",
    "        # extract and return real and imaginary\n",
    "        real = torch.real(fits)\n",
    "        real_scaled = (real - torch.tensor(scaler_real.mean).cuda()) / torch.tensor(\n",
    "            scaler_real.std\n",
    "        ).cuda()\n",
    "        imag = torch.imag(fits)\n",
    "        imag_scaled = (imag - torch.tensor(scaler_imag.mean).cuda()) / torch.tensor(\n",
    "            scaler_imag.std\n",
    "        ).cuda()\n",
    "        out = torch.stack((real_scaled, imag_scaled), 2)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trains NN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, params_train, params_test = train_test_split(\n",
    "    scaled_data, scaled_params, test_size=0.7, random_state=42\n",
    ")\n",
    "\n",
    "params_test_unscaled = params_scaler.inverse_transform(params_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_pre_trained_models:\n",
    "  max_num_of_updates = scaled_data.shape[0] // 16 * 10\n",
    "  output_tensor_dict = {}\n",
    "  seed = 0\n",
    "  noise_reshaped = resample(noise.reshape(-1, 165), 80, axis=1)\n",
    "  noise_2d = np.stack((np.real(noise_reshaped), np.imag(noise_reshaped)), axis=2)\n",
    "  noise_train, noise_test = train_test_split(noise_2d, test_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_pre_trained_models:\n",
    "  for noise_factor in noise_levels:\n",
    "      noise_factor = float(noise_factor)\n",
    "      random_seed(seed=42)\n",
    "      torch.cuda.empty_cache()\n",
    "      model = SHO_Model().cuda()\n",
    "\n",
    "      loss_func = torch.nn.MSELoss()\n",
    "      batch_size = 128\n",
    "      data_noise = scaled_data + noise_2d * noise_factor\n",
    "      data_train_noise = data_train + noise_train * noise_factor\n",
    "      data_test_noise = data_test + noise_test * noise_factor\n",
    "\n",
    "      optimizer = torch.optim.Adam(model.parameters())\n",
    "      train_dataloader = DataLoader(data_train_noise, batch_size=batch_size)\n",
    "      epochs = max_num_of_updates * batch_size // scaled_data.shape[0] // 16\n",
    "      print(f\"Training with batch size = {batch_size}, noise factor = {noise_factor}\")\n",
    "      start_time_training = time.time()\n",
    "      for epoch in range(epochs):\n",
    "          start_time = time.time()\n",
    "          train_loss = 0.\n",
    "          total_num = 0\n",
    "\n",
    "          model.train()\n",
    "\n",
    "          for train_batch in train_dataloader:\n",
    "              pred = model(train_batch.double().cuda())\n",
    "              optimizer.zero_grad()\n",
    "              loss = loss_func(train_batch.double().cuda(), pred)\n",
    "              loss.backward(create_graph=True)\n",
    "              train_loss += loss.item() * pred.shape[0]\n",
    "              total_num += pred.shape[0]\n",
    "              optimizer.step()\n",
    "\n",
    "          train_loss /= total_num\n",
    "          torch.save(model.state_dict(), f'./Trained Models/SHO Fitter/model_noise_{noise_factor}_bs128.pt')\n",
    "\n",
    "          print(\"epoch : {}/{}, recon loss = {:.8f}\".format(epoch + 1, epochs, train_loss))\n",
    "          print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "      print(f\"Training with batch size={batch_size} took {time.time() - start_time_training} seconds\\n\")\n",
    "\n",
    "      del train_dataloader\n",
    "      del data_noise\n",
    "      del data_train_noise\n",
    "      del data_test_noise\n",
    "      del model\n",
    "      gc.collect()\n",
    "      torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computes fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise_level in noise_levels:\n",
    "    SHO_Fitter(f'data_file_noise_{noise_level}.h5', force=True)\n",
    "    print(f'Computation for noise level={noise_level} is done!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uses Pre-computed Noisy SHO Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: download from Zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_pre_computed_vars:\n",
    "  !unzip noisy_sho_fits.zip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapid_fitting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c58f42fd11d8ae4df132d3c425059695e86ccc63a852aa66615442730ca8b1fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
