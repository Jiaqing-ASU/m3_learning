{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hysteresis Loops Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "# sys.path.append(\"/home/ferroelectric/m3_learning/m3_learning/src\")\n",
    "sys.path.append('../../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing set for seaborn\n",
      "Pytorch seed was set to 42\n",
      "Numpy seed was set to 42\n",
      "tensorflow seed was set to 42\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import h5py\n",
    "import pyUSID as usid\n",
    "\n",
    "from src.m3_learning.be.processing import fit_loop_function, loop_lsqf\n",
    "from m3_learning.be.loop_fitter import loop_fitting_function_torch\n",
    "from m3_learning.viz.layout import subfigures\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from m3_learning.nn.random import random_seed\n",
    "from m3_learning.viz.style import set_style\n",
    "from m3_learning.viz.printing import printer\n",
    "from m3_learning.be.viz import Viz\n",
    "from m3_learning.be.dataset import BE_Dataset\n",
    "from m3_learning.be.nn import SHO_fit_func_nn, SHO_Model\n",
    "from m3_learning.nn.Fitter1D.Fitter1D import Multiscale1DFitter, Model\n",
    "# from m3_learning.nn.Fitter1D.Fitter1D_new import Multiscale1DFitter, Model\n",
    "from m3_learning.be.filters import clean_interpolate\n",
    "\n",
    "printing = printer(basepath = './Figures/')\n",
    "\n",
    "\n",
    "set_style(\"printing\")\n",
    "random_seed(seed=42)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No spectroscopic datasets found as attributes of /Measurement_000/Channel_000/Position_Indices\n",
      "No position datasets found as attributes of /Raw_Data-SHO_Fit_000/Spectroscopic_Values\n",
      "/\n",
      "├ Measurement_000\n",
      "  ---------------\n",
      "  ├ Channel_000\n",
      "    -----------\n",
      "    ├ Bin_FFT\n",
      "    ├ Bin_Frequencies\n",
      "    ├ Bin_Indices\n",
      "    ├ Bin_Step\n",
      "    ├ Bin_Wfm_Type\n",
      "    ├ Excitation_Waveform\n",
      "    ├ Noise_Floor\n",
      "    ├ Position_Indices\n",
      "    ├ Position_Values\n",
      "    ├ Raw_Data\n",
      "    ├ Spatially_Averaged_Plot_Group_000\n",
      "      ---------------------------------\n",
      "      ├ Bin_Frequencies\n",
      "      ├ Max_Response\n",
      "      ├ Mean_Spectrogram\n",
      "      ├ Min_Response\n",
      "      ├ Spectroscopic_Parameter\n",
      "      ├ Step_Averaged_Response\n",
      "    ├ Spatially_Averaged_Plot_Group_001\n",
      "      ---------------------------------\n",
      "      ├ Bin_Frequencies\n",
      "      ├ Max_Response\n",
      "      ├ Mean_Spectrogram\n",
      "      ├ Min_Response\n",
      "      ├ Spectroscopic_Parameter\n",
      "      ├ Step_Averaged_Response\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n",
      "    ├ UDVS\n",
      "    ├ UDVS_Indices\n",
      "├ Raw_Data-SHO_Fit_000\n",
      "  --------------------\n",
      "  ├ Fit\n",
      "  ├ Fit-Loop_Fit_000\n",
      "    ----------------\n",
      "    ├ Fit\n",
      "    ├ Fit_Loop_Parameters\n",
      "    ├ Guess\n",
      "    ├ Guess_Loop_Parameters\n",
      "    ├ Loop_Metrics\n",
      "    ├ Loop_Metrics_Indices\n",
      "    ├ Loop_Metrics_Values\n",
      "    ├ Projected_Loops\n",
      "    ├ completed_fit_positions\n",
      "    ├ completed_guess_positions\n",
      "    ├ completed_positions\n",
      "  ├ Guess\n",
      "  ├ Spectroscopic_Indices\n",
      "  ├ Spectroscopic_Values\n",
      "  ├ completed_fit_positions\n",
      "  ├ completed_guess_positions\n",
      "Datasets and datagroups within the file:\n",
      "------------------------------------\n",
      "/\n",
      "/Measurement_000\n",
      "/Measurement_000/Channel_000\n",
      "/Measurement_000/Channel_000/Bin_FFT\n",
      "/Measurement_000/Channel_000/Bin_Frequencies\n",
      "/Measurement_000/Channel_000/Bin_Indices\n",
      "/Measurement_000/Channel_000/Bin_Step\n",
      "/Measurement_000/Channel_000/Bin_Wfm_Type\n",
      "/Measurement_000/Channel_000/Excitation_Waveform\n",
      "/Measurement_000/Channel_000/Noise_Floor\n",
      "/Measurement_000/Channel_000/Position_Indices\n",
      "/Measurement_000/Channel_000/Position_Values\n",
      "/Measurement_000/Channel_000/Raw_Data\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000/Bin_Frequencies\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000/Max_Response\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000/Mean_Spectrogram\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000/Min_Response\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000/Spectroscopic_Parameter\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_000/Step_Averaged_Response\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001/Bin_Frequencies\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001/Max_Response\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001/Mean_Spectrogram\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001/Min_Response\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001/Spectroscopic_Parameter\n",
      "/Measurement_000/Channel_000/Spatially_Averaged_Plot_Group_001/Step_Averaged_Response\n",
      "/Measurement_000/Channel_000/Spectroscopic_Indices\n",
      "/Measurement_000/Channel_000/Spectroscopic_Values\n",
      "/Measurement_000/Channel_000/UDVS\n",
      "/Measurement_000/Channel_000/UDVS_Indices\n",
      "/Raw_Data-SHO_Fit_000\n",
      "/Raw_Data-SHO_Fit_000/Fit\n",
      "/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000\n",
      "/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000/Fit\n",
      "/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000/Fit_Loop_Parameters\n",
      "/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000/Guess\n",
      "/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000/Guess_Loop_Parameters\n",
      "/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000/Loop_Metrics\n",
      "/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000/Loop_Metrics_Indices\n",
      "/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000/Loop_Metrics_Values\n",
      "/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000/Projected_Loops\n",
      "/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000/completed_fit_positions\n",
      "/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000/completed_guess_positions\n",
      "/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000/completed_positions\n",
      "/Raw_Data-SHO_Fit_000/Guess\n",
      "/Raw_Data-SHO_Fit_000/Spectroscopic_Indices\n",
      "/Raw_Data-SHO_Fit_000/Spectroscopic_Values\n",
      "/Raw_Data-SHO_Fit_000/completed_fit_positions\n",
      "/Raw_Data-SHO_Fit_000/completed_guess_positions\n",
      "\n",
      "The main dataset:\n",
      "------------------------------------\n",
      "<HDF5 file \"data_raw_unmod.h5\" (mode r+)>\n",
      "\n",
      "The ancillary datasets:\n",
      "------------------------------------\n",
      "<HDF5 dataset \"Position_Indices\": shape (3600, 2), type \"<u4\">\n",
      "<HDF5 dataset \"Position_Values\": shape (3600, 2), type \"<f4\">\n",
      "<HDF5 dataset \"Spectroscopic_Indices\": shape (4, 63360), type \"<u4\">\n",
      "<HDF5 dataset \"Spectroscopic_Values\": shape (4, 63360), type \"<f4\">\n",
      "\n",
      "Metadata or attributes in a datagroup\n",
      "------------------------------------\n",
      "BE_actual_duration_[s] : 0.004\n",
      "BE_amplitude_[V] : 1\n",
      "BE_auto_smoothing : auto smoothing on\n",
      "BE_band_edge_smoothing_[s] : 4832.1\n",
      "BE_band_edge_trim : 0.094742\n",
      "BE_band_width_[Hz] : 200000\n",
      "BE_bins_per_band : 0\n",
      "BE_center_frequency_[Hz] : 1310000\n",
      "BE_desired_duration_[s] : 0.004\n",
      "BE_phase_content : chirp-sinc hybrid\n",
      "BE_phase_variation : 1\n",
      "BE_points_per_BE_wave : 0\n",
      "BE_repeats : 4\n",
      "FORC_V_high1_[V] : 1\n",
      "FORC_V_high2_[V] : 10\n",
      "FORC_V_low1_[V] : -1\n",
      "FORC_V_low2_[V] : -10\n",
      "FORC_num_of_FORC_cycles : 1\n",
      "FORC_num_of_FORC_repeats : 1\n",
      "File_MDAQ_version : MDAQ_VS_090915_01\n",
      "File_date_and_time : 18-Sep-2015 18:32:14\n",
      "File_file_name : SP128_NSO\n",
      "File_file_path : C:\\Users\\Asylum User\\Documents\\Users\\Agar\\SP128_NSO\\\n",
      "File_file_suffix : 99\n",
      "IO_AO_amplifier : 10\n",
      "IO_AO_range_[V] : +/- 10\n",
      "IO_Analog_Input_1 : +/- .1V, FFT\n",
      "IO_Analog_Input_2 : off\n",
      "IO_Analog_Input_3 : off\n",
      "IO_Analog_Input_4 : off\n",
      "IO_DAQ_platform : NI 6115\n",
      "IO_rate_[Hz] : 4000000\n",
      "VS_amplitude_[V] : 16\n",
      "VS_cycle_fraction : full\n",
      "VS_cycle_phase_shift : 0\n",
      "VS_measure_in_field_loops : in and out-of-field\n",
      "VS_mode : DC modulation mode\n",
      "VS_number_of_cycles : 2\n",
      "VS_offset_[V] : 0\n",
      "VS_read_voltage_[V] : 0\n",
      "VS_set_pulse_amplitude[V] : 0\n",
      "VS_set_pulse_duration[s] : 0.002\n",
      "VS_step_edge_smoothing_[s] : 0.001\n",
      "VS_steps_per_full_cycle : 96\n",
      "data_type : BEPSData\n",
      "grid_/single : grid\n",
      "grid_contact_set_point_[V] : 1\n",
      "grid_current_col : 1\n",
      "grid_current_row : 1\n",
      "grid_cycle_time_[s] : 10\n",
      "grid_measuring : 0\n",
      "grid_moving : 0\n",
      "grid_num_cols : 60\n",
      "grid_num_rows : 60\n",
      "grid_settle_time_[s] : 0.15\n",
      "grid_time_remaining_[h;m;s] : 10\n",
      "grid_total_time_[h;m;s] : 10\n",
      "grid_transit_set_point_[V] : 0.1\n",
      "grid_transit_time_[s] : 0.15\n",
      "num_bins : 165\n",
      "num_pix : 3600\n",
      "num_udvs_steps : 384\n"
     ]
    }
   ],
   "source": [
    "# Specify the filename and the path to save the file\n",
    "filename = 'data_raw_unmod.h5'\n",
    "save_path = \"./Data\"\n",
    "\n",
    "data_path = save_path + \"/\" + filename\n",
    "\n",
    "# instantiate the dataset object\n",
    "dataset = BE_Dataset(data_path)\n",
    "\n",
    "# print the contents of the file\n",
    "dataset.print_be_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performs SHO fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider calling test() to check results before calling compute() which computes on the entire dataset and writes results to the HDF5 file\n",
      "\n",
      "Note: Loop_Fit has already been performed with the same parameters before. These results will be returned by compute() by default. Set override to True to force fresh computation\n",
      "\n",
      "[<HDF5 group \"/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000\" (11 members)>]\n",
      "\n",
      "Note: Loop_Fit has already been performed with the same parameters before. These results will be returned by compute() by default. Set override to True to force fresh computation\n",
      "\n",
      "[<HDF5 group \"/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000\" (11 members)>]\n",
      "Returned previously computed results at /Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000\n",
      "\n",
      "Note: Loop_Fit has already been performed with the same parameters before. These results will be returned by compute() by default. Set override to True to force fresh computation\n",
      "\n",
      "[<HDF5 group \"/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000\" (11 members)>]\n",
      "Returned previously computed results at /Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alk224/miniconda3/envs/alibek/lib/python3.9/site-packages/pyUSID/io/hdf_utils/simple.py:888: UserWarning: A dataset named: Guess_Loop_Parameters already exists in group: /Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000\n",
      "  warn('A dataset named: {} already exists in group: {}'.format(dset_name, h5_group.name))\n",
      "/home/alk224/miniconda3/envs/alibek/lib/python3.9/site-packages/pyUSID/io/hdf_utils/simple.py:888: UserWarning: A dataset named: Fit_Loop_Parameters already exists in group: /Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000\n",
      "  warn('A dataset named: {} already exists in group: {}'.format(dset_name, h5_group.name))\n"
     ]
    }
   ],
   "source": [
    "h5_loop_fit, h5_loop_group = dataset.LSQF_Loop_Fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize LSQF fit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No spectroscopic datasets found as attributes of /Measurement_000/Channel_000/Position_Indices\n",
      "No position datasets found as attributes of /Raw_Data-SHO_Fit_000/Spectroscopic_Values\n"
     ]
    }
   ],
   "source": [
    "# insatiate the visualization object\n",
    "image_scalebar = [2000, 500, \"nm\", \"br\"]\n",
    "\n",
    "# instantiate the dataset object\n",
    "dataset = BE_Dataset(data_path)\n",
    "\n",
    "BE_viz = Viz(dataset, printing, verbose=True, \n",
    "             SHO_ranges = [(0,1.5e-4), (1.31e6, 1.33e6), (-300, 300), (-np.pi, np.pi)], \n",
    "             image_scalebar = image_scalebar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No spectroscopic datasets found as attributes of /Measurement_000/Channel_000/Position_Indices\n",
      "No position datasets found as attributes of /Raw_Data-SHO_Fit_000/Spectroscopic_Values\n",
      "./Figures/hysteresis_comparison.png\n",
      "./Figures/hysteresis_comparison.svg\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJEAAAB6CAYAAAC/W7FiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnmUlEQVR4nO2deZxcRbn3v89sPTM9e5JJJhsJhEASCZgJKoIRvXjz5qLAFXejIIS8DtxFvCBh+RBWxZdXvYosYlC45F4BAUFBERAVENkyYMhKSCAymcme2We6Z6n7R53qqj5zepvpYRLo3+fTnz59qk7V6a5fP89Tz/NUHVFKkUMOI0HeWN9ADoc+ciTKYcTIkSiHESNHohxGjByJchgxciTKYcQoGI1GRWQR8GFgt1LqZyLyaeAI4A1gPfBl4ADwY+A677LLgX8FipVSN4jIucBE4M9Avtue29eyZcvU1KlTs3bva9asob6+PmvtjVUf2e7n6quvvkMptSywUCmV9RdwSaJ34EKg0DuuB/4BOAVY4NVZEXBNXDvua+XKlSqbqK+vz2p7Y9VHtvsBrlIJxntUJBHg92AOx6OpEhzHYc2aNSxcuDD2efny5SxfvnwY3eXgx+23387tt99uPiYUaaNFoudF5BJgv4jUA2+IyMXAZmAjWnUdAP4GXOtdc4WIfBE4UUQOA/aKyKXA00C+195uf0f19fVcddVVo/Q1Rh9KKTa0tDO3rgIRGevbiYP7hxSRNYnqjQqJlFJPowffwH8DVznHlzrHv/BeAHG2j6+9UcM7IcXcPja0tNOwupFbly5g3uTKUetnNJGbnTm4/vrraW9v57rrrktdGbjzzju57rrruPrqq9m6dWtc2Q033JDwOndw59ZVcOvSBcytqxjeTSfBO0Wi0VJnBxXSVRn5+flcdNFF3HLLLezZs4df/OIX7NmzhxNOOIEZM2bwrW99i/POO49jjjmGww8/HIBly5YxYcIEvve97zF37lyef/55Tj/9dNauXcujjz6KUornn3+e0047jfDUo5gzqZyNOzti9yIiWZdA7zTeE5LIqIwNLe1J6w0MDHDNNdewbds2IpEIIsK2bdv48Ic/zM0338z8+fN55ZVXYgTyo6Ojg6lTp/LXv/6V+fPnc+qpp8bO/er3f6RhdSOPvNYy5F6UUqxvbjMz2yGfM0JHB+zcaT+vcSyJbdugu9t+bmmxx/39mffl4T1BonRVRn5+PldeeSU1NTW8+eabiAiRSISqqiq2bNlCQ0MD27Zti7tm1apVXHvttZx55pm88cYbKKUYHBykvLycBx98MHautqyIW5cu4JPH1A25F0Py9c1trG9uY0NzGqQfHLTH3/uePd68Gf7yF/v53nvt8UMPwfbt9vMyx+1zwgn2+MUX4fLLk/5WcUg09z9UXtn2E40FBgcH1bodrWpdU6v6yHefUq81HVDrdrSqwcFBW6m31x739Sl17rn284IF9nj1aqUuuMB+Bnt8/PFK/epXptP4Mvf43nuV+uxn4+6RJH6i94QkghGqiJHClRpKwZ499n7WrInZRXO7d/Oz40uYN7mSeZMrkR//2F63YgW8/bY+7u6GO+6wZY2N9njHDnjzzeD76OrSL4C+vqHl5rfp7ISysrS/3qiQSEQWicgKETnH+/xpEblYRP5ZRGaLyNUi8g0RKRCRG7xXvohcKCLXiMgsETlDRC4TkWu9ut8UkYWp+k4Ev8oYFpmUircptmyxx6+/bgcZ4K677GU/+AEb3mjWfba2ws9/HruffT+7O1ZPmpqY1bMfEUEpxb61G+19PvCAJgjoQU6Ezk5LFD9cEgXV6e21ZeFw4j58GC1JdIJS6gZggvf5SKXUjcBs4FR0vCwEHAs8ATzpHRd5ZZ9SSj0EbAXuBfZ7ZcOeTc6tq+DWLx6LIDSsbuT1V1+3hW+8AQcO2M8PPGCPf/hD+w9tboY777Rlq1bZ482b4yXA2rUxabOneS8Xr35J2zjRKESjMTttnIraa7wy0KR/7m/brV3kkiOIROYeXaL40dlprw2q4xIsAxIdbGEP5at7jFLqXmAdgIhcATzvXuCGPRRwxlkXcMW/nK3/zatWsX7JZxCEud27mffii6gvfYlbly5g9o++w7raFQjCnBde4M3xU7mv8TlWrFjBpd/5f9Rs3cpJJ52EvPQS91x8OWUh4dxPfIKf3H8/ddEoixYtYoE7mA4BAOjoiEmb+/uifP+MOcyuq4AmTaTY1N4dTKeNuXUVzHn1CZhUzvrmNuZ2diKmvyAS9fVBUVFyEqWSRJ2dMH68fg+HD82wB/BR7/1uEalGSyBE5FRgIToLIA5u2GN9cxsNqxv55+Y2RIRJLzSybPdMAFZ/sIRZPT2xwdu3az/L7tLT31sH9vCT51oprujlN2ubWd+0m3+qm0np5CO5f9MWNs7+Ag2nHsN9//1DunqiKKWorq5GdXayfkerJmkkgngEUErRvns/cyaVc+vSBUz4/qPU1hSDyFCyJSCiiCB9fazf2UHD6kae7utLLkV6ejSJXGnjR29vchK5ZTU1h2zY4we+et/32nsUeDRVv0ZFVP38pzz5+Bo+t38Dvy4rBxEm3LNP2xRNTQDUNL7A/fOPo+1zX2bOb7Zwydxp/OjlPdz4u02sPm4+T4WKOe2cb/DVwQEu/OgMrn/8derborTs7aXh8+cwc3Il7XsPxIh4f0krgz2DTB0c5JHXWhj3+g6qdnZoadPXZ4mTjESRSHyZ8524xKkbRJKuLqisTC6J3GsTtWHeMzCs31UeayNl3pp5BC/NUpzepqi94Rpoa9N2zwsvwIUX6rpr1zL1wvOZCtDfz8yKIsaFCzix53nu2v46+VvW8rXFx/N/nm3nD7+9mxn72rjwtCXcsWktc4yKifaw6qx6BCFv9TpWPfU6Cxa2cOPvNvGrsDDO+IJc4gSRSKlgKeV8J4CdO/YwUSmr1ly45EhmeCezq9w2smUTeclls4AtSqln0m51jHFYWT4XnzyDykde1v/u738fFi/WxwYdHfbYG7wrrrhCz75efs4629at4YSGBn6/eTMT8vO59sQPxVTMY/vbeN+UKgBUaR7LPjiFycfUcUR1MeMeVjbEkoxEPT0wMAAFBfC3v2nCf/3r1lB28OjzW/lgcxvVTbuZ4i90pYhpP2gGmq46y8bsTEQuA4qB54Cwl5ZxSECiUQ4rK9A2SjQK7XZWxOOP64FzSRSJWIK5xxC7bvHixYTz8+NmViXRHttnXx9TwwXk5eUxb3xJzD5y2xhy7P/85ps6NAGaWD6cPqsCQfjlnzcP/dJBEiagjbRJlA11ppT6tvNxE/BY2q2ONaJRyM9HRSK8vn0Ps9vbEUOOxkY49thASTTkOEFZTMUkUkV+2yad9ktL9T2Z+/KpNYDx9DFucgXj59bAw77CIKPb+H1S1fOXZajO0vITicihlSroEaaro5srf/kKHXv228EyZOro0P/UxsbkBHA/+8t6e63n1y3zE8Uv6RIRzCVRAgKICLV5Olga5zANkjCGFG69dA3rLKmz+d7rKGBVonoHJbxBCzPAdUuOJK+zE9XbawfTkKirC37zm/hBNkQzcD8HlbnESbeeG3Lo77dl7e1a1ULSQd6/az9AfIA2iBxBIY53Up0B7/fei4BlwMXpNjqC1R7/BlQD/wUsBVqB3wKTSLDaIxCRCOTnI9EoEo3QtH0X5XvamOJKou5uPWBGMqQzyNFovJ0xOGjLjEoz9fLzbb3CwviywkJbtmOHLevutn0nmT3VoOvEZSUYAvT0DD3X3a19SO65d0KdKaXu8l4/BZrSblFjxGEPYB8QTtBechiiDAxwRKkwI5zH5OI8LdYjEa0q8vL0P98jHJGITqGIRPRMyaCgIF6dmcEACIVsWX6+zcmJRuPrFRXFk8gtM+dA35eRYK7NZuANsngEiEuwMwRwg71BhEk2xc922ENE/h0dSSgEatJuUWPEYQ+l1E0ikgesABJmTAWu9jCSIBRCOjooHuhDRaPs64eagV7eemsnM8rKkPZ2PXDl5XogH3wQPvc5TQ6DUCheTZkypTQZTJk7oMMlUSQyVBINDmrCu+eSEcBFUP10Ymfd3VBampWwx0Pee1Qp1ZKkXhCyEfb4IjAPeBbozmi1x8qVWu0UFel/dCTCrr3t/PGNVk6qGOD2R17l6pJSirwyamr0QLa2Dh1kV9q4ZX192m4ImEUNkViJSGQMXpdERpoZSdTXZ4nrI4Xy0n7nQXJSuCRKQ10CkJc38rCHUmp7orJUyFLYwx8nS3+1h4geoFBIq6yBASaGhFOOncb4nX/ngvpaChsrdVlvr5Zag4OaRH4C+O0ZUxaNWgnmh6lnpv+JSGTsK3fmZmAGNBIZSiKPHBta2mm4e43+YZKRIhnBUp1LA+/upDQjiUIhpL+fCdVhpL+fqQUDSHm5tYkM2trsoG3ZAi+9FK/OXIJFo4klUTSqbQpDkkQkcm0hP4wkcg1lnySaW1fBbZ97nz6XaraVqCzVuTSQrp/o/GG1PtYoKtJEMf9kES1Z2ttR5eU0v71bT/0Nenp0/aIinTu0fXu8OuvrszOrVCQqL7fkKyyMt6v8JEpiRMeV+ab/IsLcyoL4+i7SJZExxpPF3JIgKYlEpEJETgFWD6v1sUYoFJNEMfvDk07tBcX8+plNdHY6//RIREujUMi6AFx1BtaAjkTiieLCTzCXiJ2d8Oqrth7oPv0w5HEH1k1fNUg3oOqHua6/35JzlCTRtWi76fphtT6WMLOn9natWozB6tlJFROqOXNWBWUVzlS2t1fXLy/XA2tydIICmqlsIpdEbht798KTT9p6oPv0I92ZWLqZiona7+5OXi8NpCLRJrQfZ9OwWh9LDAxo8nR0QEWFlRiedJKKCiaoCFJcbK8JIpGxifx2SzJ1FonEl7nTfxNuMW1AMImCJJHbPmhSd3VpaZmIKCUliYlYVmbTbsPh7KszEfkBMB+4DT3VPrRg1E0Qidrb9Q/o2kugB6OtTZe1tekftbhYD/bKlUN9QclsokRl/sAvJJdEQfaSuddoVNerrU0siRKVdXbChAm6rLMTJk4ctiRKNsW/UET+SSn120wbzVLY40Q0eX+H9mbnAU8rpV5O6yaiUaiu1oMwceIQSUR5Oaqjg9aScqqUQkATpr0dpk3TJOrr021EIrB7Nxx2mG0/lU1kVJ0/pyfInkkkicaNSywdjBQxJGpuHlqnqys5OUwmZG+vzq32LcxMF6nU2Tnecp1/y7DdbKz2uAstBQ8n09UeJrxhpvGuJDLT/vJyuvbs56m32tnT6ZNSRp25kmq3z8+Zrk3U3x8fK3M90cagTiSJJk1KTCKjfrq6UBMnMtDROXQZlCFRGm1kEnD1I9Wg/If3nul+diMOe4hIGDgXvfKyzzuXdLUHeGEPsDk6XV2aROafKhIjWDjSzUcXHMO4spA+X1wcr85KS+10PIhEZWXx69DcsgkTbHC3qMh6il1PdGurdnQmkkR1dXqQ3XiYQVlZTBW1lldT3d3Fr9c2c5pbp7MTjj46sSQyJIpEAmNl6YY9UkmiWcA3gQ+mqOdHsrDHb9Gqqxcd9jgFveXe34A+dNjjN8AtXp2FInKqiKwEhiztrK+v5+WXX469li9fbolijGJXEkFMikh7O+PHeTuF9PfbgSkt1eQYHIwnkYh+meh9MsPaSCl/GMVIhWhUE3XatMSSqK5Ok6m7e+ggh8OxpPyqSeMBuPH3m4e2YWyioFRZp40gSbR8+fLY78rQqEMMyQKw/4MOQ2xVSv0oUb0gZCnscZbvmpSrPeJggqVJSER3t43YRyJQVQV//7u9zrRhpIZxGzz+uN55Y+bMxDZROGzzil59FSZP1mUdHTqganxSxv7yw5VEZlmzK1GcmZV4BLhtab1eFWJgDOsXX7Tedpf0ps0EkihdJJNEt6AlxAdFZPywexgrmB/NTyJjL5WVxc6pwUH27W1DVVZqI9P82KYN8082JHrhBW2EJrKJwM7qolF49FHYt0+f7+yMD/hOnpx49mRsoqC18a5h7ZUN2efItYmCpI0hUYapH34kyyd61jOOvwkcWumxSsVLIjOLcldfGAIUFLC3tZu/rt/B3oLS+H+sUUXd3XqmZMr27oVdu5KTyG2jtdVKG+O/Mups4sTg2JmRIolIlEIVMTgYPzsLSjQzNlGGGzj4kcxP1CAitUqpXcAdItIw7F7GAn5JZKbbjmFtMhDHlxZw0rQyxk+t1QPqV2fd3XZAQyEtVXbv1o68RJtDuSTq64tf62/KkpFocNC6KFJJIj85Skq0o9T4f1yHoguXiCOQRMlmZ78Avioi04C/A3cnqXtwwaSqhkL2n+8mj7kBUhEEqMrzBs0NdRgiuiQykshM/5XSA27STwxcEoGWRv6yRCQy7ZSXp6fOEpGjv1/beYmIEg7rP0Mkou2vYSKZs7EVyMigPqjgpm0YyeJKotJSTTAz+L29+gd3bSKjzrq6YOpUG+HPz9eGtZug5mY5ulmPhrDpkig/34ZFAuyeGJKpM1Nm2khUr6xM23bGRhwm3n35ROZf7CZz+UnU328J4JBIlZVBXx/KJYBRZyZEUFSk1cWePbb9p54amq1oIveRiJZiLomM/6qtTXuK+/stod0ZVCoSJZBEvcWlDHpuA1VSYm2iZEQcJXWGiJwGTAHWKqX+km6jWQp7zA+6Rin1n0k77+/X03Y398clkb1J++6R6K3uQWYCW1ojzE6kzsyU30isjg646SZYskT36yfDgQNw+OHw5z/bvqurrbFdVaXP9fRocrq5R2VlyW2iXbsCJczWbti/djsfATbs7mKeUsnV3ihO8UE7G7vIPACbjdUeia5JDjeZ3sDNTvRvQZyXp22aSIQZk/V6hCOnjhs6O3NtomhUX5Ofr22K9ev1eVeKmOO334ZZs+JncVVVmlxtbTp+BbFQTJw/KF11ZggQjaIKCjhs+gROnKizE2LLioKkTTK7KgOkCntMRRMh073psrHJVVrX+MMe//rlL3NWUVE8WYIkkYGp19+PeJJLiovtsqNQKD4a7hJFRJPIkM2U9fXBzTfH9mdk2rT4PmtqhkoiE+PLz7ehEXMfafqJ6OpCwmHKaipjiWaxZUXJZmcJbKJsbXJ1PXoFxp9T1PNjxKs9gPkJronDkNUeLS3w8MPWOQhazZipeNBm6KauWZpjyDAwoM+5NpGbpQiaREccoQfeXPfAAzB3rl7z39QE83yCvLpaS6JIRBMFrCTKy7MkMvfd2altJxdBUsQQJSg3yFV75ncJip15bg/IwrM9vHyiKnT86jTg7ER1/Ril1R5XkQ5cg9ogaApuYNSZu77LGNZmFYhfnbmhjl274OMf1/nYc+boQdi8GT7/eX1tU5Oe2bmoqrL7SRtSm7wnEUsiU5ZIEvnVmSGKP0Ri2giHNWlNOmxQ2CMoTpcCyTzWFwJ/VUo1oHN6Dg0YEgUtJjSzMxeGXE7Z+r09WiWZ6XZPj5YeQU7BPXtg4UJ46y3dx1/+AkcdBVOm6MyBpiZ9bO6joMBKIhcmBcUk0rlwiRIkRcyfxpVEfhIFlQW5CYaRFpLKsJ4vImeRRB8edHBJ5C4O9EsngwASNaz29oV2fTZgA6duWwMDMH26VqOhENx3H5x5pibS5s16oMvLdd2ODj1AxrB2YdRZEImMJMrPtyklRp2Z7+DWc8sMgqSUm09kSDoMIzsViS4GNgBXZtTqWMJv5IId+GSSyKg84LbPztO+IpdEbhiluFhPxY1kGhiwqm9gQJcdfTRs2hSfCnLggJZCZorvwhjWyUgUDtv8pSBpYwiQTJ259pJrWLsLJDMkUSrD+tuAADOAMzJqeaxgfhD/GnrXuQg20SvAVppbE9I+G9cgN22Y9l2VZCTdH/4Ap5yiwyK1tVrVhcP6usJC7eWuqUkuicyxC1fCmLJEKsuQzdvgdEiZS7CCgvjfwa2XAZJKIqXUhUqpbwD3ZdTqWMIMciJJBEP9RiZMYVSFcfwVF2tpI2JXfpgArZ9ERUXwyitw3HG2Xbesuhq2btXZAEE2kTGsU0kikw2ZaAaWyCZyJVGyhPxheK9Teax/gPbX9CSrd1AhEtGDlGj5s4glg/ns3+Gjp0cTyETDCwuttzqRJJo5U7fpT843cbXaWtiwIbEkam/XbgSltCRz4UqiXbv0u/Gcu8jUsA7CKKiz25RSm0VkTroNisg44CKgRyl1jXduNpmHOlrRoZMOtLtgOfC497iGxPCrs4ICbUe4NpFZ8WGckmbzByO5jCQyabImvOFXZ3v32qyAJUtg0aJ4H5K5BxEdaN20STseg2wWo85MiMKFS6Ldu/UgB/m7UhnWxl5qawu+3tTLljoTkdOBBi9+lkku0cno7fmaRcTsa5RxqEMp9UfgBmAcEEWTqTRl70Z9mAF0CWAQCukfsrjY+oeKijR5RLREKSmxkigUivcRGRJt2WIT8ufMgSOP1P2bATrqKOsknDgRNm7UkihoAFMZ1oYARhIFwSVKkDozKtEQ0Y+iIti/P6uSqBX9TI1Whu50HwcROQNreG8EXs3gHpKFOr4F/FQp1QRc4q32iIM/7HHj/Pl8bMGC+AE36/HNbMssDTLSx5DOkK2nB1VcTJvKp7K7G3FJZBL5i4r0FL621hrW/hzmhQvtk4FqazXpxo0L/hWMJBoYGEoik3VQVqaN80Qk6uzUjs1kHutwODERTZlHomyEPSaiA6/z0IP7zUQVPRXzEMTU2X+g1dl+EfkCdoVH2qEOEfm/6DVnJ4jIJuCTgLMRovfN/GGPVausOjME6ejQdo1ZNRpEIvNcjFAIenroyivkT01dfGDnASY7W9TE/D5KwTPPaAnjtmEMcdCqy8TNamv1eyISGUnU35941WsyAhQUaCly1FGpbaKWlmBpY9TljBlAFsIeSqn7GMasTCm1D7jM+XyPd3iVUy3dUMdPnOPX0roBv03kSiIzuK46c2dzHR2xtevhqnJOqpvGuMLBeJVoovegPdLHHx9PIhOk9cOQyARcXRQWavuqvDw5icrKtDQLIpFrLzkkWt/cplMwzGTBqMQgEhmS+mN9KZAqdhZTL0qphJLooIJLImMHGBIZmEWKQcZ2RQW0tiLFxYyfUGXzhow6g/gMydpaa3sF2V8GE7ysmCDPeUWFVnuGRPv3x+8+a2DU2ezZQ8tcVeTYRA2rG20QMy8vI3WWLlLFzm5C2zg3ZdTqWMK1cUw8Ksiw9m/mYAhQWamn3yZBrL8/bv1+nM0zaZI2nI30caWeH2ZggghWUaHJWlam+0hk9ySziVxyODbRrUsXBNdLps6yHDv7Knp6/S8ZtTqWcNWTsTP8A2vUmcmzBittKiosiczSI7NFTXW1rmPU4uzZMRuKgoKhEsuFOeeWmTQQk5gWCllplIhE6UgRx3E6ZC2aq/aC2khUlgSpSHQAnQqyS0SSPw/8YIHJCzIOQr8kGhjQBDEEc3czc9RZbIC7uy15amriDdavfCXeSZkpiUpK9HtFhS0z/ZoQiAtDnkQEM+RzU3/9CIftzrdBZeZPkwFSkagavZy5BPhGRi0fDIhGh0qivj6760fQbiGuOhNBdXVxoKgU5ZLIeKQXL46f1hviJiKRyb02MCQykqiw0A58IqJAYlXkv86078Jcm24baSCVx/ox4AOApLseP4sea4V+ZOdTaLdAXJtpwRi+27fbwTOLGXfssD4esFJk6lS9jOaII0Ap2va388TuAZYUtVNeUxO/TQzEe7rz8qwh7kcoBKefHl9W6vlOjSRyJUeQJEpGgKCydOulU5YEqSTRF9A7dDycQZsnkwWPNXqBQB/6mWtBbaaGIYxRZ8bGMfsWuYZyfr62bSoqrOcaqByMcvKHZlMW9RLTjC/HkMnvYPTvAmIQpOr86sxFInWTqCxISplz7kwvmTQbJolSSaI30Z7KPmB7okqj4bFWSj0BPOF5qTcmutjvsf5JXZ11rZpHLpjQhXkgTEWFVWe7dtnGIhGtWpzgrHR3UzttEjzpqTOzctb4e/zpsokS4PwkEhkqiVwMxyYCa1NBjAyqtBTp6EAphaRDRO89W/sTzUM/qCVg7xMLpdRDSqmzlVJnoyXGuUBdgMc61Z5Ebzge65M8ArUBf3LbdPv2709UX+99V3e5tLu5gyuJ3DX6oO0lM93WXyx+TXxNjbWjDFFSSSJ362OXRKGQ/ccnk0RBkiWZFHGljneuv0STdUNLe3Jp5pNEI96fyMNedOCzL0W9GLLssX7WOb6MTOHuCOKur3clkSFWZaWVRO4u9iUlmkRdXfq9vDzexvKv/nBJZIjjHpuyggJrUCeTROXl8evQ3HcXhgCuXeWdK6goh9279Bo08wdJRkQjIdNEKkn0OloavT+jVscaZqmPIYx5yIpZkGi82IZEJuXVzObMzvv9/foHrarSZVOnwrnn2hwhSC6J/IsZ3VliYWFyEgURJh0SBbRhVJiYLQVT1I97VFcaSEWiX6HTL47NqNWxhLs3UV6e/icXFNgQh/cIKwYH7TqvvDz94yqlB7SkRA+651NSlZUM9PVrg620NDFRID4BLohExiA/5RR43/v0sSGTCyOJXMIYCeGeM+orDRsHsJIqmSTKEMliZyuAdqDmkImbGZiBDIU0KUwszX2VlWmyuOeKivSAGhIVFUFJCa9HC5g4KOxoadce4MLCeJvI/eea3CQYuke2SegHa6RD+pLItOsOtpEsadg4ge2nOpcGkkmiTrQUykxBjjXcvYlMGMEQyhClqMiSy5QVF1vSmeOQTtiffdQ0wuWldl27uc5/bD67BHNnY+4gudelsonc7wbBKi6NKbtSivXNbanrZ4hkAdgfo43el0Xkh8NqfazgSqKysnhSmIGtrLTHxcX6ZcjlSqKjjkJKSymsKLfr2l1yuMepylxCuGWZTueDHIpp+JU2tLTbNXVuG0ESLgOkWu0xoJR6UCn178NqfazgSiKTQ+NXZ341Z0gUDlvpVVQEy5db28pguCTyqyZT5vp2DIJsIg+qsDAmUXpDJQwODrKtO2CJuE9Kza2rsFF9l6TDDHcYZGaGp4Eshj3eBk5CJ+t/m3QT9c3usGaQjEoLUmd+SVRcbJc5u2oJ9GMcvMdlzi0s1CmzkB0SBXm4fQPrPqpzw84OGlY38qf8fLZ0w5uvtfDgU9u509+GT52JiI3quwQz32U0JNEwcTLZSdR/GZ1Z+UcySdSHeEmUyLiurBwqicrLtd3x/vcHEsCogz19xBPAn5c0HBKdFrcX/hCbKE4VKbjly+9HwmFmHlbLJ4+p47LPL2QIkhjW61v7UEqhwmF6QyX6kQ5jSSIROUNE7hSRO9EbY2WCZIn6ZwIPKKU2KKUuQedcx8GEPcxrTWOjlUSlpVqyuMZ1MpvIDNw55wQSwKiDCTXlmRvWXhvGuFWFhbEyVVhI24DEP5vDSKBwGCXCnEnlMVXU8N+NiEhsL6K8vDyOnDlJ13fbSGIvNdyzlg0t7URCJbzZ43mzfVH/22+/Pfa7MoKwR1oYjbCH1/REpdRuETlGRC4lQaL+kLCHkUTGceiqM1c6mUE+4QQdtffPnnzqzKgDcYnjJ0pJiZ3G+6WUI8129tpHPmzc18uLOzr1QHrY2D7Auh2ttPTn011UwsadHTFVdOvSBXqm6NgzGzt0cp3bxvaIxKSNN06xsluWLgAFoaoKpk8bz5xJ5azzrjX1shX2yBjZDHsopa7w3l8j3UT9c86xOdAzZ+pzH/uYXsFQVgZPP60l1OWXa4O5pCS2uiGh8ZygTCnFhr092kYyZQ4RVVERzd391A0OsrGlgzopikmUSb/eHGtDFRSycPZEqjwXgsrL4+u/XE+kMMQD4TBFVRXWvQDxdo1HkDnT9fq2OZPKY8n5//+5HXzi2GYW9OUxFU0wc62I0LC6kd8WhCgrL2VdSztfveNFGoF1O1rJy8tjbl2FnZEmwbtv99jp0/VzyaZP1xtuApx6qibO9OmwdKndG7G0FC66yF57/vn2eNYs61EGvarDg6qsZHPHAOub22i4Zy17+8WqqXA4dry1LcrPXmzmkddaOPeul/n937usRCkqYmtrRLfxP68wGA7bATv/fG752odYdVY9k6fVUlheFjyYJikfYlsFbvSMboDPLDqKGx/bzKAXgDUEM8cXLZ5NuKaStvwQKLs135t7u2lY3Rgn1ZLh3UeiTOEmmU2fbo8nTdIqzuALX4gdbviH0zjviWYE4dal9ey54BuaDKsb2brk0zGV1T+xji+d/Y988pg67jhrIYtO+0hMojT1KlY+vs1rYwE1tTZNSkpLmTe9hvdNqdKPXk809XYkkXFEutP4RcfN4Lav1DNt2gQoLIwj2COvtXDjY5vZ0ZfHsy09iAj/dc4HAPjk/DqrMtOBUuqQfq1cuVK90xgcHFTrdrTG3j/y3afUuqbW2Dm3PGEb0aha13TA1mlqstc995ytuG2bUt/5jv0M9vgzn1Hqu98NLgOltm/Xx888o1R1dax9Beqk7/5BPfxqkxo87zy192vn2ftw21Buc1ylEoxB1m2i9wJcf4v55/vthyGrLPxtFBYyb0qVPTFlChs8aXbr0gV2z+eZM2HFClvPPf7Up6w9Bzqoa/ChD1k7rroaZs2Ku+/bltbrey4rY1xRUeINHtJAjkQjRJwDD+sUTNcodeESMiG+6cTCq6vjfTv1zix88WLrCR8/Hr70JVt26aX2npcsiU9kuyzztK0xV0cjfY2FOkuGmHrb0Tr6nfX3K+WqzI0bnRtZp9TAgK23Y4ct6+nJuCuSqLOsG9YiMk5EviMiVzrnZovI1d5DiQtE5AbvlS8iF4rINSIyy3Na3uZds0hEVojIOUFtjhacnOJhIR1pMtI+YsjPj1dDRx9tj+fN4/ZVq2w98+RHCI7VjQAHVdhD6bjYW9417qMdgtocFYx0gGMOySSqLGskSoF3qp+s2ERZXO3hP58SgU+j9rZDyWFkSHe1hyiV1lilDd/+RNd6YY9XgC+io/g3E78/0b+hd+6/G6hDb2x1AzrEcQKwG/i126avv1WAb6vUEaGeJC7+Q6iPbPczVSm1LKgg6yTK4b2HnMc6hxEjR6IcRowciTyIyAwReUhEJvndEFnuJ+a6yGa7Tvsni8g9rltlNPpxkSORB6XUW3iblzLUDZFN+J9KmVUopf6Enh27bpVRxXs67OFzTTwL9L8D3b7rZjK52ZkHzzVxE3pK/EMcN4RSaiDhhZn3swjPdaGU+nm22nXaPxYtgZ5EL4A4oJQa1SVfORLlMGLkbKIcRowciXIYMXIkymHEyJEohxEjR6IMISKrxMvzEJGfiS/nQ0T+U0TOFpHjRtDHx0XkxIC+5onImSP6AqOA97SfaJj4HbBYRJrRiy+vEJH9QJVS6nqvzpHAdBHZCyxBP7FpA3pd3VfQO+O2Ai955Qq4Syll1t39o1JqhYhMcvtSSq0Xka8AD7wTXzRd5CRR5ngY/disrwJ3ojcBuxn9cD+DLej0lRb0FspN6EdyLQFu9coAPg9s8+q5y8/Nqkl/X27ZQYMciTKEUqof2AHkKaXagP0icgF6l12DrWiCTAGmAQNoqf8Y+imWp6O9478EJnnXvO5cH03QV6zsYELO2fgOQkRKgaXoR8SvVkptSFDv40CvUuo53/m5wByl1EGlznIkymHEyKmzHEaMHIlyGDFyJMphxMiRKIcRI0eiHEaMHIlyGDH+Fy2MJvaPdspXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 147.6x113.76 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "BE_viz.hysteresis_comparison(data = ['LSQF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loop_param_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No spectroscopic datasets found as attributes of /Measurement_000/Channel_000/Position_Indices\n",
      "No position datasets found as attributes of /Raw_Data-SHO_Fit_000/Spectroscopic_Values\n"
     ]
    }
   ],
   "source": [
    "data, voltage = dataset.get_hysteresis(scaled=True, loop_interpolated = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<m3_learning.util.preprocessing.global_scaler at 0x7f3f9f18f7f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.hysteresis_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No spectroscopic datasets found as attributes of /Measurement_000/Channel_000/Position_Indices\n",
      "No position datasets found as attributes of /Raw_Data-SHO_Fit_000/Spectroscopic_Values\n",
      "Using GPU A100-SXM4-40GB\n",
      "Pytorch seed was set to 42\n",
      "Numpy seed was set to 42\n",
      "tensorflow seed was set to 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alk224/miniconda3/envs/alibek/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at ../torch/csrc/autograd/engine.cpp:1151.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam\n",
      "epoch : 1/600, recon loss = 0.15932465\n",
      "--- 1.4157049655914307 seconds ---\n",
      "Epoch 1, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 2/600, recon loss = 0.10540325\n",
      "--- 0.11212158203125 seconds ---\n",
      "Epoch 2, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 3/600, recon loss = 0.07236160\n",
      "--- 0.11109232902526855 seconds ---\n",
      "Epoch 3, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 4/600, recon loss = 0.05490667\n",
      "--- 0.10817456245422363 seconds ---\n",
      "Epoch 4, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 5/600, recon loss = 0.04736421\n",
      "--- 0.10851716995239258 seconds ---\n",
      "Epoch 5, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 6/600, recon loss = 0.04256225\n",
      "--- 0.10821819305419922 seconds ---\n",
      "Epoch 6, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 7/600, recon loss = 0.03869602\n",
      "--- 0.10810279846191406 seconds ---\n",
      "Epoch 7, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 8/600, recon loss = 0.03554474\n",
      "--- 0.10753202438354492 seconds ---\n",
      "Epoch 8, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 9/600, recon loss = 0.06933050\n",
      "--- 0.10820150375366211 seconds ---\n",
      "Epoch 9, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 10/600, recon loss = 0.04797182\n",
      "--- 0.10704874992370605 seconds ---\n",
      "Epoch 10, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 11/600, recon loss = 0.03420994\n",
      "--- 0.10729384422302246 seconds ---\n",
      "Epoch 11, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 12/600, recon loss = 0.03106465\n",
      "--- 0.10618019104003906 seconds ---\n",
      "Epoch 12, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 13/600, recon loss = 0.02955689\n",
      "--- 0.10707879066467285 seconds ---\n",
      "Epoch 13, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 14/600, recon loss = 0.02819703\n",
      "--- 0.10669493675231934 seconds ---\n",
      "Epoch 14, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 15/600, recon loss = 0.02706333\n",
      "--- 0.10732007026672363 seconds ---\n",
      "Epoch 15, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 16/600, recon loss = 0.02596887\n",
      "--- 0.10623574256896973 seconds ---\n",
      "Epoch 16, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 17/600, recon loss = 0.02488360\n",
      "--- 0.10707545280456543 seconds ---\n",
      "Epoch 17, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 18/600, recon loss = 0.02392972\n",
      "--- 0.10650396347045898 seconds ---\n",
      "Epoch 18, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 19/600, recon loss = 0.02283245\n",
      "--- 0.1073448657989502 seconds ---\n",
      "Epoch 19, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 20/600, recon loss = 0.02185367\n",
      "--- 0.10990095138549805 seconds ---\n",
      "Epoch 20, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 21/600, recon loss = 0.02084852\n",
      "--- 0.10977458953857422 seconds ---\n",
      "Epoch 21, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 22/600, recon loss = 0.01961414\n",
      "--- 0.11147356033325195 seconds ---\n",
      "Epoch 22, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 23/600, recon loss = 0.01859485\n",
      "--- 0.10935735702514648 seconds ---\n",
      "Epoch 23, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 24/600, recon loss = 0.01763264\n",
      "--- 0.10941052436828613 seconds ---\n",
      "Epoch 24, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 25/600, recon loss = 0.01697246\n",
      "--- 0.10876989364624023 seconds ---\n",
      "Epoch 25, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 26/600, recon loss = 0.01645173\n",
      "--- 0.10930967330932617 seconds ---\n",
      "Epoch 26, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 27/600, recon loss = 0.01599092\n",
      "--- 0.10873603820800781 seconds ---\n",
      "Epoch 27, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 28/600, recon loss = 0.01575898\n",
      "--- 0.10820460319519043 seconds ---\n",
      "Epoch 28, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 29/600, recon loss = 0.01533669\n",
      "--- 0.10842061042785645 seconds ---\n",
      "Epoch 29, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 30/600, recon loss = 0.01518679\n",
      "--- 0.10855650901794434 seconds ---\n",
      "Epoch 30, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 31/600, recon loss = 0.01493621\n",
      "--- 0.10774421691894531 seconds ---\n",
      "Epoch 31, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 32/600, recon loss = 0.01473631\n",
      "--- 0.10850381851196289 seconds ---\n",
      "Epoch 32, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 33/600, recon loss = 0.01454800\n",
      "--- 0.10787153244018555 seconds ---\n",
      "Epoch 33, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 34/600, recon loss = 0.01446697\n",
      "--- 0.10780620574951172 seconds ---\n",
      "Epoch 34, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 35/600, recon loss = 0.01424659\n",
      "--- 0.10783767700195312 seconds ---\n",
      "Epoch 35, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 36/600, recon loss = 0.01418299\n",
      "--- 0.1090705394744873 seconds ---\n",
      "Epoch 36, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 37/600, recon loss = 0.01404825\n",
      "--- 0.10783743858337402 seconds ---\n",
      "Epoch 37, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 38/600, recon loss = 0.01396523\n",
      "--- 0.10798525810241699 seconds ---\n",
      "Epoch 38, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 39/600, recon loss = 0.01373876\n",
      "--- 0.10820770263671875 seconds ---\n",
      "Epoch 39, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 40/600, recon loss = 0.01366645\n",
      "--- 0.10805845260620117 seconds ---\n",
      "Epoch 40, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 41/600, recon loss = 0.01359129\n",
      "--- 0.10774493217468262 seconds ---\n",
      "Epoch 41, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 42/600, recon loss = 0.01351086\n",
      "--- 0.10782575607299805 seconds ---\n",
      "Epoch 42, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 43/600, recon loss = 0.01347060\n",
      "--- 0.1081855297088623 seconds ---\n",
      "Epoch 43, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 44/600, recon loss = 0.01330900\n",
      "--- 0.1081240177154541 seconds ---\n",
      "Epoch 44, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 45/600, recon loss = 0.01326056\n",
      "--- 0.10826468467712402 seconds ---\n",
      "Epoch 45, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 46/600, recon loss = 0.01330582\n",
      "--- 0.10838747024536133 seconds ---\n",
      "Epoch 46, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 47/600, recon loss = 0.01320252\n",
      "--- 0.10816669464111328 seconds ---\n",
      "Epoch 47, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 48/600, recon loss = 0.01309489\n",
      "--- 0.1084442138671875 seconds ---\n",
      "Epoch 48, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 49/600, recon loss = 0.01303848\n",
      "--- 0.10808658599853516 seconds ---\n",
      "Epoch 49, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 50/600, recon loss = 0.01295071\n",
      "--- 0.10793113708496094 seconds ---\n",
      "Epoch 50, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 51/600, recon loss = 0.01294860\n",
      "--- 0.10795402526855469 seconds ---\n",
      "Epoch 51, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 52/600, recon loss = 0.01284722\n",
      "--- 0.10833311080932617 seconds ---\n",
      "Epoch 52, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 53/600, recon loss = 0.01285431\n",
      "--- 0.10809946060180664 seconds ---\n",
      "Epoch 53, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 54/600, recon loss = 0.01283349\n",
      "--- 0.10841131210327148 seconds ---\n",
      "Epoch 54, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 55/600, recon loss = 0.01285282\n",
      "--- 0.1083672046661377 seconds ---\n",
      "Epoch 55, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 56/600, recon loss = 0.01268678\n",
      "--- 0.10857963562011719 seconds ---\n",
      "Epoch 56, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 57/600, recon loss = 0.01263221\n",
      "--- 0.10825037956237793 seconds ---\n",
      "Epoch 57, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 58/600, recon loss = 0.01258118\n",
      "--- 0.10818743705749512 seconds ---\n",
      "Epoch 58, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 59/600, recon loss = 0.01256912\n",
      "--- 0.10769939422607422 seconds ---\n",
      "Epoch 59, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 60/600, recon loss = 0.01252115\n",
      "--- 0.10760903358459473 seconds ---\n",
      "Epoch 60, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 61/600, recon loss = 0.01284233\n",
      "--- 0.10860633850097656 seconds ---\n",
      "Epoch 61, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 62/600, recon loss = 0.01259307\n",
      "--- 0.10726785659790039 seconds ---\n",
      "Epoch 62, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 63/600, recon loss = 0.01240571\n",
      "--- 0.1074821949005127 seconds ---\n",
      "Epoch 63, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 64/600, recon loss = 0.01239687\n",
      "--- 0.10776281356811523 seconds ---\n",
      "Epoch 64, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 65/600, recon loss = 0.01243028\n",
      "--- 0.10770058631896973 seconds ---\n",
      "Epoch 65, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 66/600, recon loss = 0.01230528\n",
      "--- 0.10730981826782227 seconds ---\n",
      "Epoch 66, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 67/600, recon loss = 0.01220953\n",
      "--- 0.10765814781188965 seconds ---\n",
      "Epoch 67, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 68/600, recon loss = 0.01215676\n",
      "--- 0.10731124877929688 seconds ---\n",
      "Epoch 68, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 69/600, recon loss = 0.01211811\n",
      "--- 0.10745453834533691 seconds ---\n",
      "Epoch 69, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 70/600, recon loss = 0.01212501\n",
      "--- 0.10744214057922363 seconds ---\n",
      "Epoch 70, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 71/600, recon loss = 0.01206978\n",
      "--- 0.10780620574951172 seconds ---\n",
      "Epoch 71, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 72/600, recon loss = 0.01208196\n",
      "--- 0.10783839225769043 seconds ---\n",
      "Epoch 72, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 73/600, recon loss = 0.01234038\n",
      "--- 0.1076970100402832 seconds ---\n",
      "Epoch 73, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 74/600, recon loss = 0.01203665\n",
      "--- 0.10830926895141602 seconds ---\n",
      "Epoch 74, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 75/600, recon loss = 0.01190950\n",
      "--- 0.1077108383178711 seconds ---\n",
      "Epoch 75, Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam\n",
      "epoch : 76/600, recon loss = 0.01186767\n",
      "--- 0.10826683044433594 seconds ---\n",
      "Epoch 76, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 77/600, recon loss = 0.01184208\n",
      "--- 0.10817265510559082 seconds ---\n",
      "Epoch 77, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 78/600, recon loss = 0.01182740\n",
      "--- 0.10807013511657715 seconds ---\n",
      "Epoch 78, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 79/600, recon loss = 0.01188235\n",
      "--- 0.10778427124023438 seconds ---\n",
      "Epoch 79, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 80/600, recon loss = 0.01200589\n",
      "--- 0.1081395149230957 seconds ---\n",
      "Epoch 80, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 81/600, recon loss = 0.01170689\n",
      "--- 0.10792708396911621 seconds ---\n",
      "Epoch 81, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 82/600, recon loss = 0.01164363\n",
      "--- 0.10805749893188477 seconds ---\n",
      "Epoch 82, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 83/600, recon loss = 0.01151652\n",
      "--- 0.10792732238769531 seconds ---\n",
      "Epoch 83, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 84/600, recon loss = 0.01148369\n",
      "--- 0.10833859443664551 seconds ---\n",
      "Epoch 84, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 85/600, recon loss = 0.01139293\n",
      "--- 0.1110985279083252 seconds ---\n",
      "Epoch 85, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 86/600, recon loss = 0.01134886\n",
      "--- 0.10813212394714355 seconds ---\n",
      "Epoch 86, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 87/600, recon loss = 0.01132436\n",
      "--- 0.10703921318054199 seconds ---\n",
      "Epoch 87, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 88/600, recon loss = 0.01126886\n",
      "--- 0.1077885627746582 seconds ---\n",
      "Epoch 88, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 89/600, recon loss = 0.01115153\n",
      "--- 0.1071021556854248 seconds ---\n",
      "Epoch 89, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 90/600, recon loss = 0.01114091\n",
      "--- 0.10706901550292969 seconds ---\n",
      "Epoch 90, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 91/600, recon loss = 0.01101452\n",
      "--- 0.10774898529052734 seconds ---\n",
      "Epoch 91, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 92/600, recon loss = 0.01098763\n",
      "--- 0.1072232723236084 seconds ---\n",
      "Epoch 92, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 93/600, recon loss = 0.01091367\n",
      "--- 0.10744738578796387 seconds ---\n",
      "Epoch 93, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 94/600, recon loss = 0.01083093\n",
      "--- 0.10741734504699707 seconds ---\n",
      "Epoch 94, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 95/600, recon loss = 0.01077359\n",
      "--- 0.10744738578796387 seconds ---\n",
      "Epoch 95, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 96/600, recon loss = 0.01097089\n",
      "--- 0.10768413543701172 seconds ---\n",
      "Epoch 96, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 97/600, recon loss = 0.01069664\n",
      "--- 0.10734796524047852 seconds ---\n",
      "Epoch 97, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 98/600, recon loss = 0.01061447\n",
      "--- 0.1071615219116211 seconds ---\n",
      "Epoch 98, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 99/600, recon loss = 0.01059788\n",
      "--- 0.10721898078918457 seconds ---\n",
      "Epoch 99, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 100/600, recon loss = 0.01051779\n",
      "--- 0.10772442817687988 seconds ---\n",
      "Epoch 100, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 101/600, recon loss = 0.01053487\n",
      "--- 0.10757923126220703 seconds ---\n",
      "Epoch 101, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 102/600, recon loss = 0.01047467\n",
      "--- 0.10776805877685547 seconds ---\n",
      "Epoch 102, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 103/600, recon loss = 0.01051421\n",
      "--- 0.10788249969482422 seconds ---\n",
      "Epoch 103, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 104/600, recon loss = 0.01041108\n",
      "--- 0.10853171348571777 seconds ---\n",
      "Epoch 104, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 105/600, recon loss = 0.01030018\n",
      "--- 0.10844564437866211 seconds ---\n",
      "Epoch 105, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 106/600, recon loss = 0.01029081\n",
      "--- 0.10811114311218262 seconds ---\n",
      "Epoch 106, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 107/600, recon loss = 0.01022701\n",
      "--- 0.1086881160736084 seconds ---\n",
      "Epoch 107, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 108/600, recon loss = 0.01020315\n",
      "--- 0.11248946189880371 seconds ---\n",
      "Epoch 108, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 109/600, recon loss = 0.01014414\n",
      "--- 0.10801362991333008 seconds ---\n",
      "Epoch 109, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 110/600, recon loss = 0.01009286\n",
      "--- 0.10813426971435547 seconds ---\n",
      "Epoch 110, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 111/600, recon loss = 0.01016187\n",
      "--- 0.10810089111328125 seconds ---\n",
      "Epoch 111, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 112/600, recon loss = 0.01005514\n",
      "--- 0.10806512832641602 seconds ---\n",
      "Epoch 112, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 113/600, recon loss = 0.01003594\n",
      "--- 0.10795879364013672 seconds ---\n",
      "Epoch 113, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 114/600, recon loss = 0.01001426\n",
      "--- 0.10818099975585938 seconds ---\n",
      "Epoch 114, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 115/600, recon loss = 0.00994413\n",
      "--- 0.10754656791687012 seconds ---\n",
      "Epoch 115, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 116/600, recon loss = 0.00992267\n",
      "--- 0.1074528694152832 seconds ---\n",
      "Epoch 116, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 117/600, recon loss = 0.01004751\n",
      "--- 0.10797953605651855 seconds ---\n",
      "Epoch 117, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 118/600, recon loss = 0.00996556\n",
      "--- 0.10769510269165039 seconds ---\n",
      "Epoch 118, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 119/600, recon loss = 0.00986827\n",
      "--- 0.1077890396118164 seconds ---\n",
      "Epoch 119, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 120/600, recon loss = 0.00980694\n",
      "--- 0.10773515701293945 seconds ---\n",
      "Epoch 120, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 121/600, recon loss = 0.00975729\n",
      "--- 0.10767030715942383 seconds ---\n",
      "Epoch 121, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 122/600, recon loss = 0.00969453\n",
      "--- 0.10719013214111328 seconds ---\n",
      "Epoch 122, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 123/600, recon loss = 0.00995785\n",
      "--- 0.10758137702941895 seconds ---\n",
      "Epoch 123, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 124/600, recon loss = 0.00984660\n",
      "--- 0.10752248764038086 seconds ---\n",
      "Epoch 124, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 125/600, recon loss = 0.00968692\n",
      "--- 0.10707521438598633 seconds ---\n",
      "Epoch 125, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 126/600, recon loss = 0.00963931\n",
      "--- 0.10756754875183105 seconds ---\n",
      "Epoch 126, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 127/600, recon loss = 0.00957283\n",
      "--- 0.10759234428405762 seconds ---\n",
      "Epoch 127, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 128/600, recon loss = 0.00957905\n",
      "--- 0.1071007251739502 seconds ---\n",
      "Epoch 128, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 129/600, recon loss = 0.00953138\n",
      "--- 0.10693144798278809 seconds ---\n",
      "Epoch 129, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 130/600, recon loss = 0.00952281\n",
      "--- 0.10698819160461426 seconds ---\n",
      "Epoch 130, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 131/600, recon loss = 0.00952243\n",
      "--- 0.10738563537597656 seconds ---\n",
      "Epoch 131, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 132/600, recon loss = 0.00955455\n",
      "--- 0.11057138442993164 seconds ---\n",
      "Epoch 132, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 133/600, recon loss = 0.00951020\n",
      "--- 0.10753941535949707 seconds ---\n",
      "Epoch 133, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 134/600, recon loss = 0.00944641\n",
      "--- 0.10781717300415039 seconds ---\n",
      "Epoch 134, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 135/600, recon loss = 0.00938221\n",
      "--- 0.10808682441711426 seconds ---\n",
      "Epoch 135, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 136/600, recon loss = 0.00938656\n",
      "--- 0.10758495330810547 seconds ---\n",
      "Epoch 136, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 137/600, recon loss = 0.00935205\n",
      "--- 0.10784673690795898 seconds ---\n",
      "Epoch 137, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 138/600, recon loss = 0.00933497\n",
      "--- 0.10851478576660156 seconds ---\n",
      "Epoch 138, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 139/600, recon loss = 0.00933359\n",
      "--- 0.10764694213867188 seconds ---\n",
      "Epoch 139, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 140/600, recon loss = 0.00931796\n",
      "--- 0.10788369178771973 seconds ---\n",
      "Epoch 140, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 141/600, recon loss = 0.00931902\n",
      "--- 0.1074981689453125 seconds ---\n",
      "Epoch 141, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 142/600, recon loss = 0.00935445\n",
      "--- 0.10759282112121582 seconds ---\n",
      "Epoch 142, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 143/600, recon loss = 0.00930015\n",
      "--- 0.10753583908081055 seconds ---\n",
      "Epoch 143, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 144/600, recon loss = 0.00926558\n",
      "--- 0.10778594017028809 seconds ---\n",
      "Epoch 144, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 145/600, recon loss = 0.00926167\n",
      "--- 0.10815858840942383 seconds ---\n",
      "Epoch 145, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 146/600, recon loss = 0.00923334\n",
      "--- 0.1085042953491211 seconds ---\n",
      "Epoch 146, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 147/600, recon loss = 0.00934165\n",
      "--- 0.10807466506958008 seconds ---\n",
      "Epoch 147, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 148/600, recon loss = 0.00925724\n",
      "--- 0.10804343223571777 seconds ---\n",
      "Epoch 148, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 149/600, recon loss = 0.00920847\n",
      "--- 0.10778045654296875 seconds ---\n",
      "Epoch 149, Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam\n",
      "epoch : 150/600, recon loss = 0.00917618\n",
      "--- 0.10807347297668457 seconds ---\n",
      "Epoch 150, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 151/600, recon loss = 0.00917560\n",
      "--- 0.1074681282043457 seconds ---\n",
      "Epoch 151, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 152/600, recon loss = 0.00926434\n",
      "--- 0.1072530746459961 seconds ---\n",
      "Epoch 152, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 153/600, recon loss = 0.00925382\n",
      "--- 0.10724616050720215 seconds ---\n",
      "Epoch 153, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 154/600, recon loss = 0.00919905\n",
      "--- 0.10712766647338867 seconds ---\n",
      "Epoch 154, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 155/600, recon loss = 0.00915850\n",
      "--- 0.10862350463867188 seconds ---\n",
      "Epoch 155, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 156/600, recon loss = 0.00911408\n",
      "--- 0.10747504234313965 seconds ---\n",
      "Epoch 156, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 157/600, recon loss = 0.00911010\n",
      "--- 0.10718655586242676 seconds ---\n",
      "Epoch 157, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 158/600, recon loss = 0.00909832\n",
      "--- 0.10801911354064941 seconds ---\n",
      "Epoch 158, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 159/600, recon loss = 0.00907769\n",
      "--- 0.10730910301208496 seconds ---\n",
      "Epoch 159, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 160/600, recon loss = 0.00912603\n",
      "--- 0.10770010948181152 seconds ---\n",
      "Epoch 160, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 161/600, recon loss = 0.00918718\n",
      "--- 0.10724902153015137 seconds ---\n",
      "Epoch 161, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 162/600, recon loss = 0.00908940\n",
      "--- 0.10806894302368164 seconds ---\n",
      "Epoch 162, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 163/600, recon loss = 0.00910960\n",
      "--- 0.10814714431762695 seconds ---\n",
      "Epoch 163, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 164/600, recon loss = 0.00913274\n",
      "--- 0.10815787315368652 seconds ---\n",
      "Epoch 164, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 165/600, recon loss = 0.00907248\n",
      "--- 0.10821199417114258 seconds ---\n",
      "Epoch 165, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 166/600, recon loss = 0.00902139\n",
      "--- 0.10808682441711426 seconds ---\n",
      "Epoch 166, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 167/600, recon loss = 0.00909076\n",
      "--- 0.1081535816192627 seconds ---\n",
      "Epoch 167, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 168/600, recon loss = 0.00903920\n",
      "--- 0.10772514343261719 seconds ---\n",
      "Epoch 168, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 169/600, recon loss = 0.00900917\n",
      "--- 0.10755443572998047 seconds ---\n",
      "Epoch 169, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 170/600, recon loss = 0.00897481\n",
      "--- 0.10772299766540527 seconds ---\n",
      "Epoch 170, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 171/600, recon loss = 0.00900682\n",
      "--- 0.10777735710144043 seconds ---\n",
      "Epoch 171, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 172/600, recon loss = 0.00908505\n",
      "--- 0.1079263687133789 seconds ---\n",
      "Epoch 172, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 173/600, recon loss = 0.00898101\n",
      "--- 0.1075894832611084 seconds ---\n",
      "Epoch 173, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 174/600, recon loss = 0.00895980\n",
      "--- 0.10752224922180176 seconds ---\n",
      "Epoch 174, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 175/600, recon loss = 0.00897127\n",
      "--- 0.10762643814086914 seconds ---\n",
      "Epoch 175, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 176/600, recon loss = 0.00895693\n",
      "--- 0.10781216621398926 seconds ---\n",
      "Epoch 176, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 177/600, recon loss = 0.00894757\n",
      "--- 0.10932397842407227 seconds ---\n",
      "Epoch 177, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 178/600, recon loss = 0.00895944\n",
      "--- 0.10749340057373047 seconds ---\n",
      "Epoch 178, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 179/600, recon loss = 0.00893838\n",
      "--- 0.10807514190673828 seconds ---\n",
      "Epoch 179, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 180/600, recon loss = 0.00892529\n",
      "--- 0.1078348159790039 seconds ---\n",
      "Epoch 180, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 181/600, recon loss = 0.00889681\n",
      "--- 0.10843920707702637 seconds ---\n",
      "Epoch 181, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 182/600, recon loss = 0.00907368\n",
      "--- 0.10838437080383301 seconds ---\n",
      "Epoch 182, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 183/600, recon loss = 0.00897872\n",
      "--- 0.10860729217529297 seconds ---\n",
      "Epoch 183, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 184/600, recon loss = 0.00898329\n",
      "--- 0.10813450813293457 seconds ---\n",
      "Epoch 184, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 185/600, recon loss = 0.00890528\n",
      "--- 0.10856771469116211 seconds ---\n",
      "Epoch 185, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 186/600, recon loss = 0.00891604\n",
      "--- 0.10834479331970215 seconds ---\n",
      "Epoch 186, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 187/600, recon loss = 0.00888189\n",
      "--- 0.10739707946777344 seconds ---\n",
      "Epoch 187, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 188/600, recon loss = 0.00887559\n",
      "--- 0.10746908187866211 seconds ---\n",
      "Epoch 188, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 189/600, recon loss = 0.00919117\n",
      "--- 0.10761141777038574 seconds ---\n",
      "Epoch 189, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 190/600, recon loss = 0.00891335\n",
      "--- 0.10745811462402344 seconds ---\n",
      "Epoch 190, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 191/600, recon loss = 0.00885084\n",
      "--- 0.10758733749389648 seconds ---\n",
      "Epoch 191, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 192/600, recon loss = 0.00886570\n",
      "--- 0.10780143737792969 seconds ---\n",
      "Epoch 192, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 193/600, recon loss = 0.00884142\n",
      "--- 0.11011242866516113 seconds ---\n",
      "Epoch 193, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 194/600, recon loss = 0.00890800\n",
      "--- 0.10779690742492676 seconds ---\n",
      "Epoch 194, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 195/600, recon loss = 0.00883508\n",
      "--- 0.10783100128173828 seconds ---\n",
      "Epoch 195, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 196/600, recon loss = 0.00884288\n",
      "--- 0.10763359069824219 seconds ---\n",
      "Epoch 196, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 197/600, recon loss = 0.00879879\n",
      "--- 0.10831093788146973 seconds ---\n",
      "Epoch 197, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 198/600, recon loss = 0.00880157\n",
      "--- 0.10820984840393066 seconds ---\n",
      "Epoch 198, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 199/600, recon loss = 0.00879567\n",
      "--- 0.10799646377563477 seconds ---\n",
      "Epoch 199, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 200/600, recon loss = 0.00879772\n",
      "--- 0.10929608345031738 seconds ---\n",
      "Epoch 200, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 201/600, recon loss = 0.00889610\n",
      "--- 0.10793590545654297 seconds ---\n",
      "Epoch 201, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 202/600, recon loss = 0.00887818\n",
      "--- 0.10764241218566895 seconds ---\n",
      "Epoch 202, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 203/600, recon loss = 0.00877858\n",
      "--- 0.10836434364318848 seconds ---\n",
      "Epoch 203, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 204/600, recon loss = 0.00876217\n",
      "--- 0.10788488388061523 seconds ---\n",
      "Epoch 204, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 205/600, recon loss = 0.00884103\n",
      "--- 0.10816335678100586 seconds ---\n",
      "Epoch 205, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 206/600, recon loss = 0.00880320\n",
      "--- 0.10752463340759277 seconds ---\n",
      "Epoch 206, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 207/600, recon loss = 0.00885536\n",
      "--- 0.10758852958679199 seconds ---\n",
      "Epoch 207, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 208/600, recon loss = 0.00874141\n",
      "--- 0.10788917541503906 seconds ---\n",
      "Epoch 208, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 209/600, recon loss = 0.00872049\n",
      "--- 0.10793232917785645 seconds ---\n",
      "Epoch 209, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 210/600, recon loss = 0.00871835\n",
      "--- 0.10779523849487305 seconds ---\n",
      "Epoch 210, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 211/600, recon loss = 0.00871564\n",
      "--- 0.1077430248260498 seconds ---\n",
      "Epoch 211, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 212/600, recon loss = 0.00870906\n",
      "--- 0.10775017738342285 seconds ---\n",
      "Epoch 212, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 213/600, recon loss = 0.00871242\n",
      "--- 0.10817718505859375 seconds ---\n",
      "Epoch 213, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 214/600, recon loss = 0.00871707\n",
      "--- 0.10760116577148438 seconds ---\n",
      "Epoch 214, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 215/600, recon loss = 0.00876959\n",
      "--- 0.10713887214660645 seconds ---\n",
      "Epoch 215, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 216/600, recon loss = 0.00870736\n",
      "--- 0.10742473602294922 seconds ---\n",
      "Epoch 216, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 217/600, recon loss = 0.00871691\n",
      "--- 0.10696244239807129 seconds ---\n",
      "Epoch 217, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 218/600, recon loss = 0.00872535\n",
      "--- 0.10723447799682617 seconds ---\n",
      "Epoch 218, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 219/600, recon loss = 0.00882555\n",
      "--- 0.10746145248413086 seconds ---\n",
      "Epoch 219, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 220/600, recon loss = 0.00868955\n",
      "--- 0.10723257064819336 seconds ---\n",
      "Epoch 220, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 221/600, recon loss = 0.00867495\n",
      "--- 0.10733461380004883 seconds ---\n",
      "Epoch 221, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 222/600, recon loss = 0.00865223\n",
      "--- 0.10834908485412598 seconds ---\n",
      "Epoch 222, Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam\n",
      "epoch : 223/600, recon loss = 0.00871153\n",
      "--- 0.10785913467407227 seconds ---\n",
      "Epoch 223, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 224/600, recon loss = 0.00864780\n",
      "--- 0.10703611373901367 seconds ---\n",
      "Epoch 224, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 225/600, recon loss = 0.00869086\n",
      "--- 0.10743951797485352 seconds ---\n",
      "Epoch 225, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 226/600, recon loss = 0.00866908\n",
      "--- 0.10765957832336426 seconds ---\n",
      "Epoch 226, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 227/600, recon loss = 0.00864591\n",
      "--- 0.10806846618652344 seconds ---\n",
      "Epoch 227, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 228/600, recon loss = 0.00865919\n",
      "--- 0.10756421089172363 seconds ---\n",
      "Epoch 228, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 229/600, recon loss = 0.00881725\n",
      "--- 0.10776805877685547 seconds ---\n",
      "Epoch 229, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 230/600, recon loss = 0.00873718\n",
      "--- 0.10752749443054199 seconds ---\n",
      "Epoch 230, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 231/600, recon loss = 0.00882363\n",
      "--- 0.10751652717590332 seconds ---\n",
      "Epoch 231, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 232/600, recon loss = 0.00859341\n",
      "--- 0.10802006721496582 seconds ---\n",
      "Epoch 232, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 233/600, recon loss = 0.00862182\n",
      "--- 0.10824894905090332 seconds ---\n",
      "Epoch 233, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 234/600, recon loss = 0.00860386\n",
      "--- 0.10785079002380371 seconds ---\n",
      "Epoch 234, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 235/600, recon loss = 0.00868675\n",
      "--- 0.10839176177978516 seconds ---\n",
      "Epoch 235, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 236/600, recon loss = 0.00862134\n",
      "--- 0.1080467700958252 seconds ---\n",
      "Epoch 236, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 237/600, recon loss = 0.00861617\n",
      "--- 0.10833263397216797 seconds ---\n",
      "Epoch 237, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 238/600, recon loss = 0.00856334\n",
      "--- 0.10780167579650879 seconds ---\n",
      "Epoch 238, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 239/600, recon loss = 0.00859397\n",
      "--- 0.10803699493408203 seconds ---\n",
      "Epoch 239, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 240/600, recon loss = 0.00854021\n",
      "--- 0.10791563987731934 seconds ---\n",
      "Epoch 240, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 241/600, recon loss = 0.00853882\n",
      "--- 0.10795974731445312 seconds ---\n",
      "Epoch 241, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 242/600, recon loss = 0.00852786\n",
      "--- 0.10791158676147461 seconds ---\n",
      "Epoch 242, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 243/600, recon loss = 0.00857552\n",
      "--- 0.10801386833190918 seconds ---\n",
      "Epoch 243, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 244/600, recon loss = 0.00863145\n",
      "--- 0.10794496536254883 seconds ---\n",
      "Epoch 244, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 245/600, recon loss = 0.00853842\n",
      "--- 0.10942506790161133 seconds ---\n",
      "Epoch 245, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 246/600, recon loss = 0.00853944\n",
      "--- 0.1078042984008789 seconds ---\n",
      "Epoch 246, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 247/600, recon loss = 0.00849242\n",
      "--- 0.10804224014282227 seconds ---\n",
      "Epoch 247, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 248/600, recon loss = 0.00848725\n",
      "--- 0.10797786712646484 seconds ---\n",
      "Epoch 248, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 249/600, recon loss = 0.00854154\n",
      "--- 0.10763859748840332 seconds ---\n",
      "Epoch 249, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 250/600, recon loss = 0.00849119\n",
      "--- 0.10740923881530762 seconds ---\n",
      "Epoch 250, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 251/600, recon loss = 0.00856950\n",
      "--- 0.1074976921081543 seconds ---\n",
      "Epoch 251, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 252/600, recon loss = 0.00849538\n",
      "--- 0.10726428031921387 seconds ---\n",
      "Epoch 252, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 253/600, recon loss = 0.00845710\n",
      "--- 0.10740923881530762 seconds ---\n",
      "Epoch 253, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 254/600, recon loss = 0.00853215\n",
      "--- 0.10709595680236816 seconds ---\n",
      "Epoch 254, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 255/600, recon loss = 0.00851575\n",
      "--- 0.10834407806396484 seconds ---\n",
      "Epoch 255, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 256/600, recon loss = 0.00844026\n",
      "--- 0.10747694969177246 seconds ---\n",
      "Epoch 256, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 257/600, recon loss = 0.00843687\n",
      "--- 0.10748052597045898 seconds ---\n",
      "Epoch 257, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 258/600, recon loss = 0.00844727\n",
      "--- 0.10710430145263672 seconds ---\n",
      "Epoch 258, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 259/600, recon loss = 0.00860745\n",
      "--- 0.10746932029724121 seconds ---\n",
      "Epoch 259, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 260/600, recon loss = 0.00845369\n",
      "--- 0.1076505184173584 seconds ---\n",
      "Epoch 260, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 261/600, recon loss = 0.00843906\n",
      "--- 0.1073920726776123 seconds ---\n",
      "Epoch 261, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 262/600, recon loss = 0.00841848\n",
      "--- 0.10811042785644531 seconds ---\n",
      "Epoch 262, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 263/600, recon loss = 0.00853673\n",
      "--- 0.1078488826751709 seconds ---\n",
      "Epoch 263, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 264/600, recon loss = 0.00857082\n",
      "--- 0.10769295692443848 seconds ---\n",
      "Epoch 264, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 265/600, recon loss = 0.00848796\n",
      "--- 0.10818910598754883 seconds ---\n",
      "Epoch 265, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 266/600, recon loss = 0.00858233\n",
      "--- 0.10803890228271484 seconds ---\n",
      "Epoch 266, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 267/600, recon loss = 0.00844445\n",
      "--- 0.10864710807800293 seconds ---\n",
      "Epoch 267, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 268/600, recon loss = 0.00846693\n",
      "--- 0.11044168472290039 seconds ---\n",
      "Epoch 268, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 269/600, recon loss = 0.00840418\n",
      "--- 0.10892963409423828 seconds ---\n",
      "Epoch 269, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 270/600, recon loss = 0.00835826\n",
      "--- 0.1080179214477539 seconds ---\n",
      "Epoch 270, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 271/600, recon loss = 0.00837767\n",
      "--- 0.10783934593200684 seconds ---\n",
      "Epoch 271, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 272/600, recon loss = 0.00835431\n",
      "--- 0.10833430290222168 seconds ---\n",
      "Epoch 272, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 273/600, recon loss = 0.00834439\n",
      "--- 0.10856199264526367 seconds ---\n",
      "Epoch 273, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 274/600, recon loss = 0.00833759\n",
      "--- 0.10797476768493652 seconds ---\n",
      "Epoch 274, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 275/600, recon loss = 0.00833720\n",
      "--- 0.10836219787597656 seconds ---\n",
      "Epoch 275, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 276/600, recon loss = 0.00830316\n",
      "--- 0.10831427574157715 seconds ---\n",
      "Epoch 276, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 277/600, recon loss = 0.00833864\n",
      "--- 0.10833549499511719 seconds ---\n",
      "Epoch 277, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 278/600, recon loss = 0.00833482\n",
      "--- 0.1083681583404541 seconds ---\n",
      "Epoch 278, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 279/600, recon loss = 0.00835831\n",
      "--- 0.10869240760803223 seconds ---\n",
      "Epoch 279, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 280/600, recon loss = 0.00827974\n",
      "--- 0.10781478881835938 seconds ---\n",
      "Epoch 280, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 281/600, recon loss = 0.00827307\n",
      "--- 0.10780978202819824 seconds ---\n",
      "Epoch 281, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 282/600, recon loss = 0.00828975\n",
      "--- 0.10762357711791992 seconds ---\n",
      "Epoch 282, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 283/600, recon loss = 0.00827916\n",
      "--- 0.1077125072479248 seconds ---\n",
      "Epoch 283, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 284/600, recon loss = 0.00832354\n",
      "--- 0.10767292976379395 seconds ---\n",
      "Epoch 284, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 285/600, recon loss = 0.00825312\n",
      "--- 0.10788249969482422 seconds ---\n",
      "Epoch 285, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 286/600, recon loss = 0.00827652\n",
      "--- 0.1084144115447998 seconds ---\n",
      "Epoch 286, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 287/600, recon loss = 0.00824057\n",
      "--- 0.10803008079528809 seconds ---\n",
      "Epoch 287, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 288/600, recon loss = 0.00825656\n",
      "--- 0.10733246803283691 seconds ---\n",
      "Epoch 288, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 289/600, recon loss = 0.00831278\n",
      "--- 0.10771870613098145 seconds ---\n",
      "Epoch 289, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 290/600, recon loss = 0.00825475\n",
      "--- 0.11158323287963867 seconds ---\n",
      "Epoch 290, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 291/600, recon loss = 0.00826332\n",
      "--- 0.10815954208374023 seconds ---\n",
      "Epoch 291, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 292/600, recon loss = 0.00824116\n",
      "--- 0.10788774490356445 seconds ---\n",
      "Epoch 292, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 293/600, recon loss = 0.00827930\n",
      "--- 0.10874700546264648 seconds ---\n",
      "Epoch 293, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 294/600, recon loss = 0.00833182\n",
      "--- 0.10784769058227539 seconds ---\n",
      "Epoch 294, Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam\n",
      "epoch : 295/600, recon loss = 0.00818486\n",
      "--- 0.10781979560852051 seconds ---\n",
      "Epoch 295, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 296/600, recon loss = 0.00829978\n",
      "--- 0.10828185081481934 seconds ---\n",
      "Epoch 296, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 297/600, recon loss = 0.00820972\n",
      "--- 0.10831451416015625 seconds ---\n",
      "Epoch 297, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 298/600, recon loss = 0.00820812\n",
      "--- 0.10826921463012695 seconds ---\n",
      "Epoch 298, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 299/600, recon loss = 0.00815021\n",
      "--- 0.10830950736999512 seconds ---\n",
      "Epoch 299, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 300/600, recon loss = 0.00814737\n",
      "--- 0.10815143585205078 seconds ---\n",
      "Epoch 300, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 301/600, recon loss = 0.00818392\n",
      "--- 0.10808372497558594 seconds ---\n",
      "Epoch 301, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 302/600, recon loss = 0.00836244\n",
      "--- 0.10809159278869629 seconds ---\n",
      "Epoch 302, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 303/600, recon loss = 0.00820970\n",
      "--- 0.10814619064331055 seconds ---\n",
      "Epoch 303, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 304/600, recon loss = 0.00817110\n",
      "--- 0.10792303085327148 seconds ---\n",
      "Epoch 304, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 305/600, recon loss = 0.00817011\n",
      "--- 0.10831403732299805 seconds ---\n",
      "Epoch 305, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 306/600, recon loss = 0.00815960\n",
      "--- 0.1082773208618164 seconds ---\n",
      "Epoch 306, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 307/600, recon loss = 0.00811741\n",
      "--- 0.10819673538208008 seconds ---\n",
      "Epoch 307, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 308/600, recon loss = 0.00806080\n",
      "--- 0.10831737518310547 seconds ---\n",
      "Epoch 308, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 309/600, recon loss = 0.00820234\n",
      "--- 0.11110496520996094 seconds ---\n",
      "Epoch 309, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 310/600, recon loss = 0.00809881\n",
      "--- 0.11008739471435547 seconds ---\n",
      "Epoch 310, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 311/600, recon loss = 0.00807862\n",
      "--- 0.11044073104858398 seconds ---\n",
      "Epoch 311, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 312/600, recon loss = 0.00806385\n",
      "--- 0.11004924774169922 seconds ---\n",
      "Epoch 312, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 313/600, recon loss = 0.00817559\n",
      "--- 0.11364960670471191 seconds ---\n",
      "Epoch 313, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 314/600, recon loss = 0.00806795\n",
      "--- 0.11036515235900879 seconds ---\n",
      "Epoch 314, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 315/600, recon loss = 0.00801269\n",
      "--- 0.1108407974243164 seconds ---\n",
      "Epoch 315, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 316/600, recon loss = 0.00801032\n",
      "--- 0.11054825782775879 seconds ---\n",
      "Epoch 316, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 317/600, recon loss = 0.00802317\n",
      "--- 0.11085319519042969 seconds ---\n",
      "Epoch 317, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 318/600, recon loss = 0.00799859\n",
      "--- 0.11023378372192383 seconds ---\n",
      "Epoch 318, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 319/600, recon loss = 0.00807538\n",
      "--- 0.11127448081970215 seconds ---\n",
      "Epoch 319, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 320/600, recon loss = 0.00799595\n",
      "--- 0.11093902587890625 seconds ---\n",
      "Epoch 320, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 321/600, recon loss = 0.00797187\n",
      "--- 0.11052608489990234 seconds ---\n",
      "Epoch 321, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 322/600, recon loss = 0.00799112\n",
      "--- 0.11088037490844727 seconds ---\n",
      "Epoch 322, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 323/600, recon loss = 0.00801459\n",
      "--- 0.11090564727783203 seconds ---\n",
      "Epoch 323, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 324/600, recon loss = 0.00799289\n",
      "--- 0.11072683334350586 seconds ---\n",
      "Epoch 324, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 325/600, recon loss = 0.00811136\n",
      "--- 0.11128973960876465 seconds ---\n",
      "Epoch 325, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 326/600, recon loss = 0.00819662\n",
      "--- 0.11073827743530273 seconds ---\n",
      "Epoch 326, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 327/600, recon loss = 0.00799385\n",
      "--- 0.11110997200012207 seconds ---\n",
      "Epoch 327, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 328/600, recon loss = 0.00800665\n",
      "--- 0.11132001876831055 seconds ---\n",
      "Epoch 328, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 329/600, recon loss = 0.00809088\n",
      "--- 0.11127090454101562 seconds ---\n",
      "Epoch 329, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 330/600, recon loss = 0.00852076\n",
      "--- 0.11175203323364258 seconds ---\n",
      "Epoch 330, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 331/600, recon loss = 0.00856039\n",
      "--- 0.11142706871032715 seconds ---\n",
      "Epoch 331, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 332/600, recon loss = 0.00811094\n",
      "--- 0.11135482788085938 seconds ---\n",
      "Epoch 332, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 333/600, recon loss = 0.00803604\n",
      "--- 0.11179494857788086 seconds ---\n",
      "Epoch 333, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 334/600, recon loss = 0.00796499\n",
      "--- 0.11100387573242188 seconds ---\n",
      "Epoch 334, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 335/600, recon loss = 0.00791923\n",
      "--- 0.11072492599487305 seconds ---\n",
      "Epoch 335, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 336/600, recon loss = 0.00795241\n",
      "--- 0.11061763763427734 seconds ---\n",
      "Epoch 336, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 337/600, recon loss = 0.00789289\n",
      "--- 0.11109328269958496 seconds ---\n",
      "Epoch 337, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 338/600, recon loss = 0.00787625\n",
      "--- 0.11214566230773926 seconds ---\n",
      "Epoch 338, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 339/600, recon loss = 0.00790596\n",
      "--- 0.11095499992370605 seconds ---\n",
      "Epoch 339, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 340/600, recon loss = 0.00787276\n",
      "--- 0.11072397232055664 seconds ---\n",
      "Epoch 340, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 341/600, recon loss = 0.00783851\n",
      "--- 0.111358642578125 seconds ---\n",
      "Epoch 341, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 342/600, recon loss = 0.00780624\n",
      "--- 0.11056041717529297 seconds ---\n",
      "Epoch 342, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 343/600, recon loss = 0.00779022\n",
      "--- 0.11103558540344238 seconds ---\n",
      "Epoch 343, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 344/600, recon loss = 0.00778123\n",
      "--- 0.11086797714233398 seconds ---\n",
      "Epoch 344, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 345/600, recon loss = 0.00779420\n",
      "--- 0.11098074913024902 seconds ---\n",
      "Epoch 345, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 346/600, recon loss = 0.00777529\n",
      "--- 0.11097526550292969 seconds ---\n",
      "Epoch 346, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 347/600, recon loss = 0.00785469\n",
      "--- 0.1113591194152832 seconds ---\n",
      "Epoch 347, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 348/600, recon loss = 0.00780141\n",
      "--- 0.11107087135314941 seconds ---\n",
      "Epoch 348, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 349/600, recon loss = 0.00773912\n",
      "--- 0.11087822914123535 seconds ---\n",
      "Epoch 349, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 350/600, recon loss = 0.00772692\n",
      "--- 0.11089801788330078 seconds ---\n",
      "Epoch 350, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 351/600, recon loss = 0.00774135\n",
      "--- 0.11122894287109375 seconds ---\n",
      "Epoch 351, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 352/600, recon loss = 0.00783689\n",
      "--- 0.11061835289001465 seconds ---\n",
      "Epoch 352, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 353/600, recon loss = 0.00775668\n",
      "--- 0.11125516891479492 seconds ---\n",
      "Epoch 353, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 354/600, recon loss = 0.00770705\n",
      "--- 0.11109781265258789 seconds ---\n",
      "Epoch 354, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 355/600, recon loss = 0.00764882\n",
      "--- 0.11111092567443848 seconds ---\n",
      "Epoch 355, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 356/600, recon loss = 0.00766800\n",
      "--- 0.11078166961669922 seconds ---\n",
      "Epoch 356, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 357/600, recon loss = 0.00763305\n",
      "--- 0.11108946800231934 seconds ---\n",
      "Epoch 357, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 358/600, recon loss = 0.00768738\n",
      "--- 0.11132144927978516 seconds ---\n",
      "Epoch 358, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 359/600, recon loss = 0.00766423\n",
      "--- 0.11102509498596191 seconds ---\n",
      "Epoch 359, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 360/600, recon loss = 0.00764351\n",
      "--- 0.11106204986572266 seconds ---\n",
      "Epoch 360, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 361/600, recon loss = 0.00771913\n",
      "--- 0.11185622215270996 seconds ---\n",
      "Epoch 361, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 362/600, recon loss = 0.00772153\n",
      "--- 0.11193203926086426 seconds ---\n",
      "Epoch 362, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 363/600, recon loss = 0.00765769\n",
      "--- 0.11122369766235352 seconds ---\n",
      "Epoch 363, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 364/600, recon loss = 0.00764029\n",
      "--- 0.11090326309204102 seconds ---\n",
      "Epoch 364, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 365/600, recon loss = 0.00775505\n",
      "--- 0.11297774314880371 seconds ---\n",
      "Epoch 365, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 366/600, recon loss = 0.00764767\n",
      "--- 0.11090826988220215 seconds ---\n",
      "Epoch 366, Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam\n",
      "epoch : 367/600, recon loss = 0.00762768\n",
      "--- 0.11095809936523438 seconds ---\n",
      "Epoch 367, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 368/600, recon loss = 0.00758121\n",
      "--- 0.11093449592590332 seconds ---\n",
      "Epoch 368, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 369/600, recon loss = 0.00756980\n",
      "--- 0.11108660697937012 seconds ---\n",
      "Epoch 369, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 370/600, recon loss = 0.00757151\n",
      "--- 0.11013650894165039 seconds ---\n",
      "Epoch 370, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 371/600, recon loss = 0.00770287\n",
      "--- 0.11111664772033691 seconds ---\n",
      "Epoch 371, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 372/600, recon loss = 0.00778674\n",
      "--- 0.1104588508605957 seconds ---\n",
      "Epoch 372, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 373/600, recon loss = 0.00788388\n",
      "--- 0.11076736450195312 seconds ---\n",
      "Epoch 373, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 374/600, recon loss = 0.00760721\n",
      "--- 0.1110999584197998 seconds ---\n",
      "Epoch 374, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 375/600, recon loss = 0.00758802\n",
      "--- 0.11088347434997559 seconds ---\n",
      "Epoch 375, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 376/600, recon loss = 0.00752077\n",
      "--- 0.11026263236999512 seconds ---\n",
      "Epoch 376, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 377/600, recon loss = 0.00752113\n",
      "--- 0.11093282699584961 seconds ---\n",
      "Epoch 377, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 378/600, recon loss = 0.00752727\n",
      "--- 0.11077022552490234 seconds ---\n",
      "Epoch 378, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 379/600, recon loss = 0.00756135\n",
      "--- 0.11114740371704102 seconds ---\n",
      "Epoch 379, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 380/600, recon loss = 0.00757178\n",
      "--- 0.11064481735229492 seconds ---\n",
      "Epoch 380, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 381/600, recon loss = 0.00754926\n",
      "--- 0.11133456230163574 seconds ---\n",
      "Epoch 381, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 382/600, recon loss = 0.00752736\n",
      "--- 0.11092829704284668 seconds ---\n",
      "Epoch 382, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 383/600, recon loss = 0.00782044\n",
      "--- 0.11143708229064941 seconds ---\n",
      "Epoch 383, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 384/600, recon loss = 0.00795593\n",
      "--- 0.11077380180358887 seconds ---\n",
      "Epoch 384, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 385/600, recon loss = 0.01080370\n",
      "--- 0.11122536659240723 seconds ---\n",
      "Epoch 385, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 386/600, recon loss = 0.01090917\n",
      "--- 0.11195158958435059 seconds ---\n",
      "Epoch 386, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 387/600, recon loss = 0.00884758\n",
      "--- 0.11098670959472656 seconds ---\n",
      "Epoch 387, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 388/600, recon loss = 0.00799462\n",
      "--- 0.11121201515197754 seconds ---\n",
      "Epoch 388, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 389/600, recon loss = 0.00770591\n",
      "--- 0.11156964302062988 seconds ---\n",
      "Epoch 389, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 390/600, recon loss = 0.00763366\n",
      "--- 0.11070561408996582 seconds ---\n",
      "Epoch 390, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 391/600, recon loss = 0.00759201\n",
      "--- 0.11110472679138184 seconds ---\n",
      "Epoch 391, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 392/600, recon loss = 0.00750327\n",
      "--- 0.11104202270507812 seconds ---\n",
      "Epoch 392, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 393/600, recon loss = 0.00748561\n",
      "--- 0.11072945594787598 seconds ---\n",
      "Epoch 393, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 394/600, recon loss = 0.00747316\n",
      "--- 0.11032390594482422 seconds ---\n",
      "Epoch 394, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 395/600, recon loss = 0.00746984\n",
      "--- 0.11080694198608398 seconds ---\n",
      "Epoch 395, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 396/600, recon loss = 0.00745501\n",
      "--- 0.1106710433959961 seconds ---\n",
      "Epoch 396, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 397/600, recon loss = 0.00745263\n",
      "--- 0.11077308654785156 seconds ---\n",
      "Epoch 397, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 398/600, recon loss = 0.00742596\n",
      "--- 0.11030054092407227 seconds ---\n",
      "Epoch 398, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 399/600, recon loss = 0.00741426\n",
      "--- 0.11045646667480469 seconds ---\n",
      "Epoch 399, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 400/600, recon loss = 0.00740671\n",
      "--- 0.1102440357208252 seconds ---\n",
      "Epoch 400, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 401/600, recon loss = 0.00740749\n",
      "--- 0.1111907958984375 seconds ---\n",
      "Epoch 401, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 402/600, recon loss = 0.00738735\n",
      "--- 0.11024975776672363 seconds ---\n",
      "Epoch 402, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 403/600, recon loss = 0.00736783\n",
      "--- 0.11062312126159668 seconds ---\n",
      "Epoch 403, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 404/600, recon loss = 0.00737386\n",
      "--- 0.11043834686279297 seconds ---\n",
      "Epoch 404, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 405/600, recon loss = 0.00737468\n",
      "--- 0.1105337142944336 seconds ---\n",
      "Epoch 405, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 406/600, recon loss = 0.00736311\n",
      "--- 0.11008334159851074 seconds ---\n",
      "Epoch 406, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 407/600, recon loss = 0.00737586\n",
      "--- 0.11088752746582031 seconds ---\n",
      "Epoch 407, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 408/600, recon loss = 0.00734604\n",
      "--- 0.11049056053161621 seconds ---\n",
      "Epoch 408, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 409/600, recon loss = 0.00733413\n",
      "--- 0.11110329627990723 seconds ---\n",
      "Epoch 409, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 410/600, recon loss = 0.00731174\n",
      "--- 0.1104278564453125 seconds ---\n",
      "Epoch 410, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 411/600, recon loss = 0.00731949\n",
      "--- 0.11074328422546387 seconds ---\n",
      "Epoch 411, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 412/600, recon loss = 0.00730165\n",
      "--- 0.11041593551635742 seconds ---\n",
      "Epoch 412, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 413/600, recon loss = 0.00731437\n",
      "--- 0.11043000221252441 seconds ---\n",
      "Epoch 413, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 414/600, recon loss = 0.00730314\n",
      "--- 0.1104118824005127 seconds ---\n",
      "Epoch 414, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 415/600, recon loss = 0.00734559\n",
      "--- 0.11077189445495605 seconds ---\n",
      "Epoch 415, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 416/600, recon loss = 0.00729763\n",
      "--- 0.11051416397094727 seconds ---\n",
      "Epoch 416, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 417/600, recon loss = 0.00728293\n",
      "--- 0.11059308052062988 seconds ---\n",
      "Epoch 417, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 418/600, recon loss = 0.00725981\n",
      "--- 0.11050844192504883 seconds ---\n",
      "Epoch 418, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 419/600, recon loss = 0.00727971\n",
      "--- 0.11101770401000977 seconds ---\n",
      "Epoch 419, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 420/600, recon loss = 0.00726006\n",
      "--- 0.11046600341796875 seconds ---\n",
      "Epoch 420, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 421/600, recon loss = 0.00727558\n",
      "--- 0.11046814918518066 seconds ---\n",
      "Epoch 421, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 422/600, recon loss = 0.00724418\n",
      "--- 0.11017227172851562 seconds ---\n",
      "Epoch 422, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 423/600, recon loss = 0.00723526\n",
      "--- 0.11061525344848633 seconds ---\n",
      "Epoch 423, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 424/600, recon loss = 0.00722828\n",
      "--- 0.11107039451599121 seconds ---\n",
      "Epoch 424, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 425/600, recon loss = 0.00723643\n",
      "--- 0.11089539527893066 seconds ---\n",
      "Epoch 425, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 426/600, recon loss = 0.00726747\n",
      "--- 0.11081361770629883 seconds ---\n",
      "Epoch 426, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 427/600, recon loss = 0.00722006\n",
      "--- 0.11052942276000977 seconds ---\n",
      "Epoch 427, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 428/600, recon loss = 0.00726631\n",
      "--- 0.11043667793273926 seconds ---\n",
      "Epoch 428, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 429/600, recon loss = 0.00721736\n",
      "--- 0.11085724830627441 seconds ---\n",
      "Epoch 429, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 430/600, recon loss = 0.00726537\n",
      "--- 0.1104116439819336 seconds ---\n",
      "Epoch 430, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 431/600, recon loss = 0.00720472\n",
      "--- 0.11103940010070801 seconds ---\n",
      "Epoch 431, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 432/600, recon loss = 0.00726534\n",
      "--- 0.11023402214050293 seconds ---\n",
      "Epoch 432, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 433/600, recon loss = 0.00725516\n",
      "--- 0.1110231876373291 seconds ---\n",
      "Epoch 433, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 434/600, recon loss = 0.00717075\n",
      "--- 0.11006021499633789 seconds ---\n",
      "Epoch 434, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 435/600, recon loss = 0.00717058\n",
      "--- 0.11071181297302246 seconds ---\n",
      "Epoch 435, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 436/600, recon loss = 0.00719900\n",
      "--- 0.11062049865722656 seconds ---\n",
      "Epoch 436, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 437/600, recon loss = 0.00719172\n",
      "--- 0.11047577857971191 seconds ---\n",
      "Epoch 437, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 438/600, recon loss = 0.00722840\n",
      "--- 0.11012625694274902 seconds ---\n",
      "Epoch 438, Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam\n",
      "epoch : 439/600, recon loss = 0.00719133\n",
      "--- 0.11073946952819824 seconds ---\n",
      "Epoch 439, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 440/600, recon loss = 0.00724178\n",
      "--- 0.11004281044006348 seconds ---\n",
      "Epoch 440, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 441/600, recon loss = 0.00720296\n",
      "--- 0.11023783683776855 seconds ---\n",
      "Epoch 441, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 442/600, recon loss = 0.00713808\n",
      "--- 0.10983872413635254 seconds ---\n",
      "Epoch 442, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 443/600, recon loss = 0.00717083\n",
      "--- 0.1109616756439209 seconds ---\n",
      "Epoch 443, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 444/600, recon loss = 0.00714460\n",
      "--- 0.10998082160949707 seconds ---\n",
      "Epoch 444, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 445/600, recon loss = 0.00720128\n",
      "--- 0.11020994186401367 seconds ---\n",
      "Epoch 445, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 446/600, recon loss = 0.00720219\n",
      "--- 0.10988831520080566 seconds ---\n",
      "Epoch 446, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 447/600, recon loss = 0.00716467\n",
      "--- 0.11004090309143066 seconds ---\n",
      "Epoch 447, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 448/600, recon loss = 0.00712817\n",
      "--- 0.10993432998657227 seconds ---\n",
      "Epoch 448, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 449/600, recon loss = 0.00713148\n",
      "--- 0.11039113998413086 seconds ---\n",
      "Epoch 449, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 450/600, recon loss = 0.00712172\n",
      "--- 0.10988140106201172 seconds ---\n",
      "Epoch 450, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 451/600, recon loss = 0.00711338\n",
      "--- 0.11056828498840332 seconds ---\n",
      "Epoch 451, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 452/600, recon loss = 0.00712696\n",
      "--- 0.11014270782470703 seconds ---\n",
      "Epoch 452, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 453/600, recon loss = 0.00717002\n",
      "--- 0.11113834381103516 seconds ---\n",
      "Epoch 453, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 454/600, recon loss = 0.00713326\n",
      "--- 0.11029195785522461 seconds ---\n",
      "Epoch 454, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 455/600, recon loss = 0.00710488\n",
      "--- 0.11083197593688965 seconds ---\n",
      "Epoch 455, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 456/600, recon loss = 0.00708635\n",
      "--- 0.11053967475891113 seconds ---\n",
      "Epoch 456, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 457/600, recon loss = 0.00712400\n",
      "--- 0.11120009422302246 seconds ---\n",
      "Epoch 457, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 458/600, recon loss = 0.00714637\n",
      "--- 0.11012482643127441 seconds ---\n",
      "Epoch 458, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 459/600, recon loss = 0.00713690\n",
      "--- 0.11055827140808105 seconds ---\n",
      "Epoch 459, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 460/600, recon loss = 0.00720363\n",
      "--- 0.11010074615478516 seconds ---\n",
      "Epoch 460, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 461/600, recon loss = 0.00711874\n",
      "--- 0.11081647872924805 seconds ---\n",
      "Epoch 461, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 462/600, recon loss = 0.00712911\n",
      "--- 0.11042213439941406 seconds ---\n",
      "Epoch 462, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 463/600, recon loss = 0.00713271\n",
      "--- 0.11105680465698242 seconds ---\n",
      "Epoch 463, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 464/600, recon loss = 0.00716400\n",
      "--- 0.11026811599731445 seconds ---\n",
      "Epoch 464, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 465/600, recon loss = 0.00708436\n",
      "--- 0.11066389083862305 seconds ---\n",
      "Epoch 465, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 466/600, recon loss = 0.00706436\n",
      "--- 0.11013460159301758 seconds ---\n",
      "Epoch 466, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 467/600, recon loss = 0.00707174\n",
      "--- 0.11050271987915039 seconds ---\n",
      "Epoch 467, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 468/600, recon loss = 0.00703979\n",
      "--- 0.11032462120056152 seconds ---\n",
      "Epoch 468, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 469/600, recon loss = 0.00707168\n",
      "--- 0.11064028739929199 seconds ---\n",
      "Epoch 469, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 470/600, recon loss = 0.00711458\n",
      "--- 0.11037492752075195 seconds ---\n",
      "Epoch 470, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 471/600, recon loss = 0.00707933\n",
      "--- 0.11068367958068848 seconds ---\n",
      "Epoch 471, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 472/600, recon loss = 0.00712168\n",
      "--- 0.10974597930908203 seconds ---\n",
      "Epoch 472, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 473/600, recon loss = 0.00708540\n",
      "--- 0.11020779609680176 seconds ---\n",
      "Epoch 473, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 474/600, recon loss = 0.00702734\n",
      "--- 0.10978102684020996 seconds ---\n",
      "Epoch 474, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 475/600, recon loss = 0.00702558\n",
      "--- 0.1105337142944336 seconds ---\n",
      "Epoch 475, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 476/600, recon loss = 0.00704171\n",
      "--- 0.11025762557983398 seconds ---\n",
      "Epoch 476, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 477/600, recon loss = 0.00725167\n",
      "--- 0.11091327667236328 seconds ---\n",
      "Epoch 477, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 478/600, recon loss = 0.00717346\n",
      "--- 0.11053013801574707 seconds ---\n",
      "Epoch 478, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 479/600, recon loss = 0.00713154\n",
      "--- 0.11078572273254395 seconds ---\n",
      "Epoch 479, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 480/600, recon loss = 0.00721461\n",
      "--- 0.11048388481140137 seconds ---\n",
      "Epoch 480, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 481/600, recon loss = 0.00725928\n",
      "--- 0.11060929298400879 seconds ---\n",
      "Epoch 481, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 482/600, recon loss = 0.00725495\n",
      "--- 0.11012029647827148 seconds ---\n",
      "Epoch 482, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 483/600, recon loss = 0.00708562\n",
      "--- 0.11057615280151367 seconds ---\n",
      "Epoch 483, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 484/600, recon loss = 0.00707409\n",
      "--- 0.11016488075256348 seconds ---\n",
      "Epoch 484, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 485/600, recon loss = 0.00719353\n",
      "--- 0.11042952537536621 seconds ---\n",
      "Epoch 485, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 486/600, recon loss = 0.00716143\n",
      "--- 0.10976314544677734 seconds ---\n",
      "Epoch 486, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 487/600, recon loss = 0.00704408\n",
      "--- 0.11045575141906738 seconds ---\n",
      "Epoch 487, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 488/600, recon loss = 0.00704514\n",
      "--- 0.11008453369140625 seconds ---\n",
      "Epoch 488, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 489/600, recon loss = 0.00703457\n",
      "--- 0.11078786849975586 seconds ---\n",
      "Epoch 489, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 490/600, recon loss = 0.00699706\n",
      "--- 0.11043667793273926 seconds ---\n",
      "Epoch 490, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 491/600, recon loss = 0.00702186\n",
      "--- 0.11032843589782715 seconds ---\n",
      "Epoch 491, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 492/600, recon loss = 0.00714645\n",
      "--- 0.11051726341247559 seconds ---\n",
      "Epoch 492, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 493/600, recon loss = 0.00710022\n",
      "--- 0.110992431640625 seconds ---\n",
      "Epoch 493, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 494/600, recon loss = 0.00703410\n",
      "--- 0.11005043983459473 seconds ---\n",
      "Epoch 494, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 495/600, recon loss = 0.00703846\n",
      "--- 0.1112678050994873 seconds ---\n",
      "Epoch 495, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 496/600, recon loss = 0.00699172\n",
      "--- 0.11033105850219727 seconds ---\n",
      "Epoch 496, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 497/600, recon loss = 0.00704161\n",
      "--- 0.11093640327453613 seconds ---\n",
      "Epoch 497, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 498/600, recon loss = 0.00698133\n",
      "--- 0.11016702651977539 seconds ---\n",
      "Epoch 498, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 499/600, recon loss = 0.00696382\n",
      "--- 0.11041951179504395 seconds ---\n",
      "Epoch 499, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 500/600, recon loss = 0.00696266\n",
      "--- 0.1101078987121582 seconds ---\n",
      "Epoch 500, Learning Rate: 0.001\n",
      "Adam\n",
      "epoch : 501/600, recon loss = 0.00696266\n",
      "--- 0.1106257438659668 seconds ---\n",
      "Epoch 501, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 502/600, recon loss = 0.00689450\n",
      "--- 6.818136930465698 seconds ---\n",
      "Epoch 502, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 503/600, recon loss = 0.00679854\n",
      "--- 5.174901247024536 seconds ---\n",
      "Epoch 503, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 504/600, recon loss = 0.00670936\n",
      "--- 5.859003305435181 seconds ---\n",
      "Epoch 504, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 505/600, recon loss = 0.00660662\n",
      "--- 5.5649144649505615 seconds ---\n",
      "Epoch 505, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 506/600, recon loss = 0.00660271\n",
      "--- 2.9956274032592773 seconds ---\n",
      "Epoch 506, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 507/600, recon loss = 0.00656938\n",
      "--- 2.978595018386841 seconds ---\n",
      "Epoch 507, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 508/600, recon loss = 0.00658354\n",
      "--- 3.657447576522827 seconds ---\n",
      "Epoch 508, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 509/600, recon loss = 0.00654344\n",
      "--- 6.854980707168579 seconds ---\n",
      "Epoch 509, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 510/600, recon loss = 0.00642027\n",
      "--- 5.017107725143433 seconds ---\n",
      "Epoch 510, Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trust Region CG\n",
      "epoch : 511/600, recon loss = 0.00638385\n",
      "--- 4.460279703140259 seconds ---\n",
      "Epoch 511, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 512/600, recon loss = 0.00636323\n",
      "--- 3.9843785762786865 seconds ---\n",
      "Epoch 512, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 513/600, recon loss = 0.00638197\n",
      "--- 4.577176094055176 seconds ---\n",
      "Epoch 513, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 514/600, recon loss = 0.00632375\n",
      "--- 3.0886306762695312 seconds ---\n",
      "Epoch 514, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 515/600, recon loss = 0.00631456\n",
      "--- 3.024336338043213 seconds ---\n",
      "Epoch 515, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 516/600, recon loss = 0.00630867\n",
      "--- 2.488344430923462 seconds ---\n",
      "Epoch 516, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 517/600, recon loss = 0.00630087\n",
      "--- 2.3801937103271484 seconds ---\n",
      "Epoch 517, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 518/600, recon loss = 0.00629790\n",
      "--- 2.830291271209717 seconds ---\n",
      "Epoch 518, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 519/600, recon loss = 0.00630119\n",
      "--- 2.3759188652038574 seconds ---\n",
      "Epoch 519, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 520/600, recon loss = 0.00629303\n",
      "--- 2.4765801429748535 seconds ---\n",
      "Epoch 520, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 521/600, recon loss = 0.00629254\n",
      "--- 2.902958869934082 seconds ---\n",
      "Epoch 521, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 522/600, recon loss = 0.00628715\n",
      "--- 2.4738576412200928 seconds ---\n",
      "Epoch 522, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 523/600, recon loss = 0.00628248\n",
      "--- 2.5472640991210938 seconds ---\n",
      "Epoch 523, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 524/600, recon loss = 0.00627834\n",
      "--- 2.5270872116088867 seconds ---\n",
      "Epoch 524, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 525/600, recon loss = 0.00627446\n",
      "--- 2.6792404651641846 seconds ---\n",
      "Epoch 525, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 526/600, recon loss = 0.00627373\n",
      "--- 2.374569892883301 seconds ---\n",
      "Epoch 526, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 527/600, recon loss = 0.00626867\n",
      "--- 2.756249189376831 seconds ---\n",
      "Epoch 527, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 528/600, recon loss = 0.00626625\n",
      "--- 2.6242644786834717 seconds ---\n",
      "Epoch 528, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 529/600, recon loss = 0.00626443\n",
      "--- 2.7191948890686035 seconds ---\n",
      "Epoch 529, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 530/600, recon loss = 0.00626235\n",
      "--- 2.868729829788208 seconds ---\n",
      "Epoch 530, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 531/600, recon loss = 0.00626074\n",
      "--- 2.5678088665008545 seconds ---\n",
      "Epoch 531, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 532/600, recon loss = 0.00625829\n",
      "--- 2.173102378845215 seconds ---\n",
      "Epoch 532, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 533/600, recon loss = 0.00625303\n",
      "--- 2.4000399112701416 seconds ---\n",
      "Epoch 533, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 534/600, recon loss = 0.00625223\n",
      "--- 2.2662222385406494 seconds ---\n",
      "Epoch 534, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 535/600, recon loss = 0.00625009\n",
      "--- 2.419926643371582 seconds ---\n",
      "Epoch 535, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 536/600, recon loss = 0.00624829\n",
      "--- 2.4709362983703613 seconds ---\n",
      "Epoch 536, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 537/600, recon loss = 0.00624370\n",
      "--- 3.3363099098205566 seconds ---\n",
      "Epoch 537, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 538/600, recon loss = 0.00624867\n",
      "--- 3.877342939376831 seconds ---\n",
      "Epoch 538, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 539/600, recon loss = 0.00623266\n",
      "--- 2.92531156539917 seconds ---\n",
      "Epoch 539, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 540/600, recon loss = 0.00623126\n",
      "--- 2.5460331439971924 seconds ---\n",
      "Epoch 540, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 541/600, recon loss = 0.00622721\n",
      "--- 2.662677764892578 seconds ---\n",
      "Epoch 541, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 542/600, recon loss = 0.00622674\n",
      "--- 2.5663363933563232 seconds ---\n",
      "Epoch 542, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 543/600, recon loss = 0.00622030\n",
      "--- 3.055281639099121 seconds ---\n",
      "Epoch 543, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 544/600, recon loss = 0.00622202\n",
      "--- 2.9842262268066406 seconds ---\n",
      "Epoch 544, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 545/600, recon loss = 0.00622025\n",
      "--- 1.9244012832641602 seconds ---\n",
      "Epoch 545, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 546/600, recon loss = 0.00621795\n",
      "--- 1.9272246360778809 seconds ---\n",
      "Epoch 546, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 547/600, recon loss = 0.00621959\n",
      "--- 2.151505708694458 seconds ---\n",
      "Epoch 547, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 548/600, recon loss = 0.00621524\n",
      "--- 3.096285820007324 seconds ---\n",
      "Epoch 548, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 549/600, recon loss = 0.00620696\n",
      "--- 4.729924917221069 seconds ---\n",
      "Epoch 549, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 550/600, recon loss = 0.00620833\n",
      "--- 3.774155378341675 seconds ---\n",
      "Epoch 550, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 551/600, recon loss = 0.00618900\n",
      "--- 5.033443212509155 seconds ---\n",
      "Epoch 551, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 552/600, recon loss = 0.00619642\n",
      "--- 4.395928382873535 seconds ---\n",
      "Epoch 552, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 553/600, recon loss = 0.00618411\n",
      "--- 3.6861634254455566 seconds ---\n",
      "Epoch 553, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 554/600, recon loss = 0.00618175\n",
      "--- 2.951716661453247 seconds ---\n",
      "Epoch 554, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 555/600, recon loss = 0.00617635\n",
      "--- 2.545809745788574 seconds ---\n",
      "Epoch 555, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 556/600, recon loss = 0.00617366\n",
      "--- 4.539660453796387 seconds ---\n",
      "Epoch 556, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 557/600, recon loss = 0.00623346\n",
      "--- 6.209991455078125 seconds ---\n",
      "Epoch 557, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 558/600, recon loss = 0.00617817\n",
      "--- 5.6026952266693115 seconds ---\n",
      "Epoch 558, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 559/600, recon loss = 0.00614220\n",
      "--- 4.383890390396118 seconds ---\n",
      "Epoch 559, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 560/600, recon loss = 0.00614470\n",
      "--- 3.5806844234466553 seconds ---\n",
      "Epoch 560, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 561/600, recon loss = 0.00613386\n",
      "--- 4.203394412994385 seconds ---\n",
      "Epoch 561, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 562/600, recon loss = 0.00613776\n",
      "--- 4.182968854904175 seconds ---\n",
      "Epoch 562, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 563/600, recon loss = 0.00636501\n",
      "--- 4.522886514663696 seconds ---\n",
      "Epoch 563, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 564/600, recon loss = 0.00625856\n",
      "--- 4.147479295730591 seconds ---\n",
      "Epoch 564, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 565/600, recon loss = 0.00617408\n",
      "--- 3.620772361755371 seconds ---\n",
      "Epoch 565, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 566/600, recon loss = 0.00615872\n",
      "--- 3.1969454288482666 seconds ---\n",
      "Epoch 566, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 567/600, recon loss = 0.00613425\n",
      "--- 3.1591601371765137 seconds ---\n",
      "Epoch 567, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 568/600, recon loss = 0.00612700\n",
      "--- 2.2215468883514404 seconds ---\n",
      "Epoch 568, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 569/600, recon loss = 0.00611665\n",
      "--- 2.149263381958008 seconds ---\n",
      "Epoch 569, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 570/600, recon loss = 0.00611408\n",
      "--- 2.430976629257202 seconds ---\n",
      "Epoch 570, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 571/600, recon loss = 0.00611229\n",
      "--- 2.4478681087493896 seconds ---\n",
      "Epoch 571, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 572/600, recon loss = 0.00611188\n",
      "--- 2.146304130554199 seconds ---\n",
      "Epoch 572, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 573/600, recon loss = 0.00611341\n",
      "--- 3.345536947250366 seconds ---\n",
      "Epoch 573, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 574/600, recon loss = 0.00610709\n",
      "--- 3.9808828830718994 seconds ---\n",
      "Epoch 574, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 575/600, recon loss = 0.00610951\n",
      "--- 3.439229726791382 seconds ---\n",
      "Epoch 575, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 576/600, recon loss = 0.00610405\n",
      "--- 5.996949911117554 seconds ---\n",
      "Epoch 576, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 577/600, recon loss = 0.00611693\n",
      "--- 5.727147817611694 seconds ---\n",
      "Epoch 577, Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trust Region CG\n",
      "epoch : 578/600, recon loss = 0.00610883\n",
      "--- 4.958174228668213 seconds ---\n",
      "Epoch 578, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 579/600, recon loss = 0.00608773\n",
      "--- 3.1880204677581787 seconds ---\n",
      "Epoch 579, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 580/600, recon loss = 0.00608049\n",
      "--- 3.793273687362671 seconds ---\n",
      "Epoch 580, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 581/600, recon loss = 0.00607719\n",
      "--- 2.9538674354553223 seconds ---\n",
      "Epoch 581, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 582/600, recon loss = 0.00607957\n",
      "--- 3.192932367324829 seconds ---\n",
      "Epoch 582, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 583/600, recon loss = 0.00607434\n",
      "--- 2.912527084350586 seconds ---\n",
      "Epoch 583, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 584/600, recon loss = 0.00607249\n",
      "--- 2.7655577659606934 seconds ---\n",
      "Epoch 584, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 585/600, recon loss = 0.00607110\n",
      "--- 2.6181836128234863 seconds ---\n",
      "Epoch 585, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 586/600, recon loss = 0.00606897\n",
      "--- 2.949730634689331 seconds ---\n",
      "Epoch 586, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 587/600, recon loss = 0.00606311\n",
      "--- 4.883933782577515 seconds ---\n",
      "Epoch 587, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 588/600, recon loss = 0.00606594\n",
      "--- 3.4896442890167236 seconds ---\n",
      "Epoch 588, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 589/600, recon loss = 0.00606522\n",
      "--- 3.306509017944336 seconds ---\n",
      "Epoch 589, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 590/600, recon loss = 0.00606119\n",
      "--- 3.7715260982513428 seconds ---\n",
      "Epoch 590, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 591/600, recon loss = 0.00606189\n",
      "--- 3.338202953338623 seconds ---\n",
      "Epoch 591, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 592/600, recon loss = 0.00606299\n",
      "--- 2.4039247035980225 seconds ---\n",
      "Epoch 592, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 593/600, recon loss = 0.00605956\n",
      "--- 2.684654712677002 seconds ---\n",
      "Epoch 593, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 594/600, recon loss = 0.00606125\n",
      "--- 2.6290769577026367 seconds ---\n",
      "Epoch 594, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 595/600, recon loss = 0.00605879\n",
      "--- 2.3491804599761963 seconds ---\n",
      "Epoch 595, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 596/600, recon loss = 0.00606181\n",
      "--- 2.780585289001465 seconds ---\n",
      "Epoch 596, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 597/600, recon loss = 0.00606026\n",
      "--- 2.503709077835083 seconds ---\n",
      "Epoch 597, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 598/600, recon loss = 0.00605839\n",
      "--- 2.109496831893921 seconds ---\n",
      "Epoch 598, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 599/600, recon loss = 0.00605529\n",
      "--- 4.278945446014404 seconds ---\n",
      "Epoch 599, Learning Rate: 0.001\n",
      "Trust Region CG\n",
      "epoch : 600/600, recon loss = 0.00605326\n",
      "--- 6.313573837280273 seconds ---\n",
      "Epoch 600, Learning Rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "from m3_learning.be.loop_fitter import loop_fitting_function_torch\n",
    "from m3_learning.optimizers.TrustRegion import TRCG\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "data, voltage = dataset.get_hysteresis(scaled=True, loop_interpolated = True)\n",
    "# V = np.swapaxes(np.atleast_2d(dataset.get_voltage), 0, 1).astype(np.float64)\n",
    "\n",
    "\n",
    "model_ = Multiscale1DFitter(loop_fitting_function_torch, # function \n",
    "                            voltage[:,0].squeeze(), # x data\n",
    "#                             V.squeeze(),\n",
    "                            1, # input channels\n",
    "                            9, # output parameters\n",
    "                            dataset.loop_param_scaler,\n",
    "                            loops_scaler=dataset.hysteresis_scaler)\n",
    "\n",
    "# instantiate the model\n",
    "model = Model(model_, dataset, training=True, model_basename=\"SHO_Fitter_original_data\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test = train_test_split(data.reshape(-1,96), test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "X_train = np.atleast_3d(X_train)\n",
    "\n",
    "optimizer = {\n",
    "    \"name\": \"TRCG\", \n",
    "    \"optimizer\": TRCG,\n",
    "    \"closure_size\": 1,\n",
    "    \"cgopttol\": 1e-3,\n",
    "    \"c0tr\": 0.2,\n",
    "    \"c1tr\": 0.25,\n",
    "    \"c2tr\": 0.75,\n",
    "    \"t1tr\": 0.75,\n",
    "    \"t2tr\": 2.0,\n",
    "    \"radius_max\": 5.0,  \n",
    "    \"radius_initial\": 1.0,\n",
    "    \"radius\" : 1.0,\n",
    "    \"device\": \"cuda\",\n",
    "    \"ADAM_epochs\": 500}\n",
    "\n",
    "\n",
    "train = True\n",
    "\n",
    "if train:\n",
    "    # fits the model\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        1024,\n",
    "        optimizer=optimizer,\n",
    "        epochs = 600,\n",
    "    )\n",
    "else:\n",
    "    model.load(\n",
    "        \"/home/ferroelectric/m3_learning/m3_learning/papers/2023_Rapid_Fitting/Trained Models/SHO Fitter/SHO_Fitter_original_data_model_epoch_5_train_loss_0.0449272525189978.pth\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "X_train = torch.atleast_3d(torch.tensor(X_train))\n",
    "\n",
    "\n",
    "train_pred_recon, train_pred_params_scaled, train_pred_params = model.predict(\n",
    "    X_train,\n",
    "    1024,\n",
    "    translate_params=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11520, 9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_recon.shape\n",
    "train_pred_params_scaled.shape\n",
    "train_pred_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voltage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3f9a5108e0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(voltage, X_train[i])\n",
    "plt.plot(voltage, np.atleast_2d(train_pred_recon[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Neural Network Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alk224/workspace/m3_learning/m3_learning/papers/2023_Rapid_Fitting/../../src/m3_learning/be/viz.py:999: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(true).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11520, 96, 1)\n",
      "(11520, 96, 1)\n",
      "./Figures/Figure_X_NN_validation_Train.png\n",
      "./Figures/Figure_X_NN_validation_Train.svg\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 442.8x113.76 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d1, d2, index1, mse1 = BE_viz.bmw_nn(\n",
    "    X_train,\n",
    "    prediction=model,\n",
    "    returns=True,\n",
    "    fit_type=\"hysteresis\",\n",
    "    filename=\"Figure_X_NN_validation_Train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2880, 96, 1)\n",
      "(2880, 96, 1)\n",
      "./Figures/Figure_X_NN_validation_Test.png\n",
      "./Figures/Figure_X_NN_validation_Test.svg\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 442.8x113.76 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = torch.atleast_3d(torch.tensor(X_test))\n",
    "\n",
    "d1, d2, index1, mse1 = BE_viz.bmw_nn(\n",
    "    X_test,\n",
    "    prediction=model,\n",
    "    returns=True,\n",
    "    fit_type=\"hysteresis\",\n",
    "    filename=\"Figure_X_NN_validation_Test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, Y_data = dataset.NN_data()\n",
    "\n",
    "data = (LSQF_, X_data, X_test, X_train)\n",
    "labels = [\"LSQF\", \"Full Data\", \"Test Data\", \"Train Data\"]\n",
    "\n",
    "model.print_mse(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a Random Example of the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insatiate the visualization object\n",
    "image_scalebar = [2000, 500, \"nm\", \"br\"]\n",
    "\n",
    "BE_viz = Viz(dataset, printing, verbose=True, \n",
    "             SHO_ranges = [(0,1.5e-4), (1.31e6, 1.33e6), (-300, 300), (-np.pi, np.pi)], \n",
    "             image_scalebar = image_scalebar)\n",
    "\n",
    "self = BE_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resampled': False,\n",
       " 'raw_format': 'complex',\n",
       " 'fitter': 'LSQF',\n",
       " 'scaled': False,\n",
       " 'output_shape': 'pixels',\n",
       " 'measurement_state': 'all',\n",
       " 'resampled_bins': 165,\n",
       " 'LSQF_phase_shift': None,\n",
       " 'NN_phase_shift': None,\n",
       " 'noise': 0,\n",
       " 'loop_interpolated': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No spectroscopic datasets found as attributes of /Measurement_000/Channel_000/Position_Indices\n",
      "No position datasets found as attributes of /Raw_Data-SHO_Fit_000/Spectroscopic_Values\n"
     ]
    }
   ],
   "source": [
    "out, voltage = dataset.get_hysteresis(scaled=True, loop_interpolated = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd422951f40>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(dataset.dc_voltage)\n",
    "plt.plot(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd4897c6a60>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = np.random.randint(0,60,(1))\n",
    "b = np.random.randint(0,60,(1))\n",
    "\n",
    "\n",
    "plt.plot(voltage[:,0].squeeze(), out[a,b,0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No spectroscopic datasets found as attributes of /Measurement_000/Channel_000/Position_Indices\n",
      "No position datasets found as attributes of /Raw_Data-SHO_Fit_000/Spectroscopic_Values\n"
     ]
    }
   ],
   "source": [
    "hys, bias = dataset.get_hysteresis()\n",
    "\n",
    "hys_2 = clean_interpolate(hys, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_finite_indices(arr):\n",
    "    non_finite_mask = ~np.isfinite(arr)\n",
    "    indices = np.argwhere(non_finite_mask)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 60, 4, 96)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 4), dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_non_finite_indices(hys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd489741e80>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = np.random.randint(0,60,(1))\n",
    "b = np.random.randint(0,60,(1))\n",
    "\n",
    "\n",
    "plt.plot(hys[a[0],b[0],0])\n",
    "plt.plot(hys_2[a[0],b[0],0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hysteresis_fit(self, \n",
    "                   voltage, \n",
    "                   datasets, \n",
    "                   original = True,\n",
    "                   row = None, \n",
    "                   col = None,\n",
    "                   cycle = None):\n",
    "    \n",
    "    if row is None:\n",
    "        row = np.random.randint(0, self.dataset.num_rows, 1)\n",
    "        \n",
    "    if col is None:\n",
    "        col = np.random.randint(0, self.dataset.num_cols, 1)\n",
    "        \n",
    "    if cycle is None:\n",
    "        cycle = np.random.randint(0, self.dataset.num_cycles, 1)\n",
    "    \n",
    "    fig, ax = subfigures(1,1, size = (1.25,1.25))\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mm3_learning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mviz\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layout_fig, inset_connector, add_box, subfigures, add_text_to_figure, get_axis_pos_inches, imagemap,  FigDimConverter, labelfigs, imagemap, scalebar\n\u001b[1;32m      3\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m subfigures(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m, size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.25\u001b[39m,\u001b[38;5;241m1.25\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m \u001b[43maxs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m(V, proj_nd_shifted_transposed[i[\u001b[38;5;241m0\u001b[39m], i[\u001b[38;5;241m1\u001b[39m], :, \u001b[38;5;241m3\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mog\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m          label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitial loops\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m axs\u001b[38;5;241m.\u001b[39mplot(V, loop_fit_results[:, i[\u001b[38;5;241m0\u001b[39m], i[\u001b[38;5;241m1\u001b[39m]], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit results (NumPy)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m axs\u001b[38;5;241m.\u001b[39mplot(V, np\u001b[38;5;241m.\u001b[39mreshape(loop_fitting_function_tf(func_type, V, params), \n\u001b[1;32m     10\u001b[0m                        (num_pix_1d, num_pix_1d, \u001b[38;5;241m96\u001b[39m))[i[\u001b[38;5;241m0\u001b[39m], i[\u001b[38;5;241m1\u001b[39m], :], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     11\u001b[0m          label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit results (Tensorflow)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'plot'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHgAAAByCAYAAACY/xW0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAAsTAAALEwEAmpwYAAAExUlEQVR4nO2dMYgcVRjHf1+ijSFWkXCIKB5nIyTFXOEZjWm00yKVXcCDI5WFgkkUySEaEmwCgpwHBk1lp50IgjEYvGZEa6+xyWGQgIiclX+LXS/rEHdnZmf2ki//Hwx78/bNt+/2N/vm7b3v3oQkTF727HYDTL9YcHIsODkWnBwLTo4FJ2ei4Ig4FhGfjewvR8SbEXGk36aZLrhvUgVJVyLiqZGiA5LORcQp4Npo3fn5eW1vb+/sF0VBURSNG1WWZavjMscpy5KyLAHY2tralLRQ60BJEzfg9MjPbwwfT1Xrzc3NqQuKonCcMQDXVcObpFpd9GHgSES8FRGPAL9FxBnguzZnopktdbron4AXR4ou9dcc0zWdjqK7uE4BrKysOM54yto16/bldbazZ892co0x4wFW1dU12NzdWHByLDg5FpwcC06OBSfHgpNjwcmx4ORYcHIsODkTZ5Mi4ijwNHBD0qWIWAb2A0i62G/zzLTU+QQvSToPPDTc3wscBG5UK5ZlyeLi4s62vr7eYVPvbdbX13feV6D+tN2k2QgqGRzAyeHj29W6nk2aDXQ8m7QxzL+6GREF8EBEvA782uQMNLtDnYyOq8DVkaL6k81m1/EoOjkWnBwLTo4FJ8eCk2PBybHg5Fhwciw4ORacHAtOjgUnx4KT0yaj41lgCdgYzjSZO5g2GR0vAdvA39WKzujoj1lmdHw0fHynWtcZHbOBnjM6voqI14BfmpyBZndwRkdyPIpOjgUnx4KTY8HJseDkWHByLDg5FpwcC06OBSfHgpNjwcmx4OTUWdL/aEScjohXRsrWKjfqMHcojTM6IuI4cOV2FZ3R0R9tMzomzgcD1fvPHgIOAA8DG6NPFEXB6upq3dc2DVhZWdm5JUBE1J6TryP4PxkdklYj4hjwV5uGmtnSJqMDSVf6apDpFo+ik2PBybHg5Fhwciw4ORacHAtOjgUnx4KTY8HJseDkWHByLDg5bdboOAE8CXwp6Zu+G2imo3FGh6RPgTXg8WpFZ3T0xyzX6NgHvAfcX63rNTpmAz2v0fEhg2yOxQYnoNkl2mR0nOivOaZrPIpOjgUnx4KTY8HJseDkWHByLDg5FpwcC06OBSfHgpPTqeCy7GYp6a6mGbPGocvpwibb3NxcJ9NhRVE4zhiA66rppE1Gx3FgHtiU9HnbU9DMhjr/4b8k6fxwThhgQdKFkf0dtra2NiNi30hRSbtbABRNlim4R+IU3Oqa/6x7UJs1Oqr7t56QFuq+sJkNMejSx1QYdNFLwE3gB+BRBl30z5K+6LuBZjomCjZ3N/4enJw61+D/pasRdle519U4w7I14BNJG2MPHt+eVvdrvE2cZWA/gKSLDeIcA05Kenm4vwwcBL6VdG3csdN+gqv3NVyQ9D7wxDRxNCb3ukmccavyNYnDmPs1Noyzl4GYG02CaLBs1Y8jRQcknQOemXTstIJrj7CbxBl+1VoGLk/ZnkMM3oQjU8Z5UNIHwAtTxtkj6QyDXm4aar/PUw2yuhph3ybOq8Am8LWk79vGkVT+uypfiy66+ns9Bvwu6eMp4jwHBPCHpNp/t4yIw8C7DJaOvAw8z6AnuDqpi/YoOjkeRSfHgpNjwcmx4ORYcHIsODn/AFty1RsMALR3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 147.6x113.76 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from m3_learning.viz.layout import layout_fig, inset_connector, add_box, subfigures, add_text_to_figure, get_axis_pos_inches, imagemap,  FigDimConverter, labelfigs, imagemap, scalebar\n",
    "\n",
    "fig, axs = subfigures(1,1, size = (1.25,1.25))\n",
    "\n",
    "\n",
    "axs.plot(V, proj_nd_shifted_transposed[i[0], i[1], :, 3],'og',\n",
    "         label='initial loops')\n",
    "axs.plot(V, loop_fit_results[:, i[0], i[1]], 'blue', label='fit results (NumPy)')\n",
    "axs.plot(V, np.reshape(loop_fitting_function_tf(func_type, V, params), \n",
    "                       (num_pix_1d, num_pix_1d, 96))[i[0], i[1], :], 'black', \n",
    "         label='fit results (Tensorflow)')\n",
    "axs.legend()\n",
    "axs.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,0))\n",
    "axs.set(xlabel='Voltage (V)', ylabel='Amplitude (Arb. U.)')\n",
    "axs.label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 60, 4, 9)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(dataset.file, \"r+\") as h5_f:\n",
    "    \n",
    "    out = h5_f['/Raw_Data_SHO_Fit/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000/Fit'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parm = dataset.LSQF_hysteresis_params(output_shape = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parm.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, bias = dataset.get_hysteresis(\"/Raw_Data_SHO_Fit/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000\", plotting_values=True)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "type",
     "evalue": "name 'loop_fitting_function_torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ferroelectric/m3_learning/m3_learning/papers/2023_Rapid_Fitting/5_Hysteresis_Fitter.ipynb Cell 58\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.248.36.21/home/ferroelectric/m3_learning/m3_learning/papers/2023_Rapid_Fitting/5_Hysteresis_Fitter.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m row \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.248.36.21/home/ferroelectric/m3_learning/m3_learning/papers/2023_Rapid_Fitting/5_Hysteresis_Fitter.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m parm \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mLSQF_hysteresis_params()[row, col, cycle]\u001b[39m.\u001b[39mview(\u001b[39m'\u001b[39m\u001b[39m<f4\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.248.36.21/home/ferroelectric/m3_learning/m3_learning/papers/2023_Rapid_Fitting/5_Hysteresis_Fitter.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m loop \u001b[39m=\u001b[39m loop_fitting_function_torch(bias[:, cycle], parm, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m9 parameters\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.248.36.21/home/ferroelectric/m3_learning/m3_learning/papers/2023_Rapid_Fitting/5_Hysteresis_Fitter.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m out, bias \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mget_hysteresis(\u001b[39m\"\u001b[39m\u001b[39m/Raw_Data_SHO_Fit/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000\u001b[39m\u001b[39m\"\u001b[39m, plotting_values\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.248.36.21/home/ferroelectric/m3_learning/m3_learning/papers/2023_Rapid_Fitting/5_Hysteresis_Fitter.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(bias[:, cycle]\u001b[39m.\u001b[39msqueeze(), loop\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39msqueeze(), \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loop_fitting_function_torch' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "self = dataset\n",
    "\n",
    "col = np.random.randint(0, self.num_cols, 1)\n",
    "cycle = pos = np.random.randint(0, 4, 1)\n",
    "row = 20\n",
    "\n",
    "parm = dataset.LSQF_hysteresis_params()[row, col, cycle].view('<f4')\n",
    "loop = loop_fitting_function_torch(bias[:, cycle], parm, type='9 parameters')\n",
    "out, bias = dataset.get_hysteresis(\"/Raw_Data_SHO_Fit/Raw_Data-SHO_Fit_000/Fit-Loop_Fit_000\", plotting_values=True)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(bias[:, cycle].squeeze(), loop.cpu().squeeze(), 'r')\n",
    "plt.plot(bias[:, cycle].squeeze(), out[row, col, :, cycle].squeeze(), 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erf, erfinv\n",
    "import warnings\n",
    "\n",
    "def loop_fit_function(vdc, coef_vec):\n",
    "    \"\"\"\n",
    "    9 parameter fit function\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    vdc : 1D numpy array or list\n",
    "        DC voltages\n",
    "    coef_vec : 1D numpy array or list\n",
    "        9 parameter coefficient vector\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    loop_eval : 1D numpy array\n",
    "        Loop values\n",
    "    \"\"\"\n",
    "\n",
    "    a = coef_vec[:5]\n",
    "    b = coef_vec[5:]\n",
    "    d = 1000\n",
    "\n",
    "    v1 = np.asarray(vdc[:int(len(vdc) / 2)])\n",
    "    v2 = np.asarray(vdc[int(len(vdc) / 2):])\n",
    "\n",
    "    g1 = (b[1] - b[0]) / 2 * (erf((v1 - a[2]) * d) + 1) + b[0]\n",
    "    g2 = (b[3] - b[2]) / 2 * (erf((v2 - a[3]) * d) + 1) + b[2]\n",
    "\n",
    "    y1 = (g1 * erf((v1 - a[2]) / g1) + b[0]) / (b[0] + b[1])\n",
    "    y2 = (g2 * erf((v2 - a[3]) / g2) + b[2]) / (b[2] + b[3])\n",
    "\n",
    "    f1 = a[0] + a[1] * y1 + a[4] * v1\n",
    "    f2 = a[0] + a[1] * y2 + a[4] * v2\n",
    "\n",
    "    loop_eval = np.hstack((f1, f2))\n",
    "    return loop_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bias[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_eval = loop_fit_function(bias[:,0], parm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bias[:,cycle].squeeze(), loop_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.LSQF_hysteresis_params()[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from m3_learning.be.loop_fitter import loop_fitting_function_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"/home/ferroelectric/m3_learning/m3_learning/papers/2023_Rapid_Fitting/Data/data_raw_SHO.h5\", \"r+\") as h5_f:\n",
    "    # number of pixels in the image\n",
    "    num_pix = h5_f[\"Measurement_000\"].attrs[\"num_pix\"]\n",
    "    \n",
    "    # voltage vector\n",
    "    V = np.swapaxes(np.atleast_2d(h5_f['Measurement_000']['Channel_000']['UDVS'][::2][:, 1][24:120]), 0, 1).astype(np.float64)\n",
    "    \n",
    "    params = np.array(h5_f['Fit_Loop_Parameters'][:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(dataset.hysteresis_waveform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sets path to file\n",
    "# path = r\"./\"\n",
    "\n",
    "# # Opens the data file2\n",
    "# h5_f = h5py.File(path + \"data_file.h5\", \"r+\")\n",
    "\n",
    "\n",
    "# # number of pixels in the image\n",
    "# num_pix = h5_f[\"Measurement_000\"].attrs[\"num_pix\"]\n",
    "# #dataset.num_pix\n",
    "\n",
    "# num_pix_1d = int(np.sqrt(num_pix))\n",
    "# #dataset.num_pix\n",
    "\n",
    "\n",
    "# # number of DC voltage steps\n",
    "# voltage_steps = h5_f[\"Measurement_000\"].attrs[\"num_udvs_steps\"]\n",
    "\n",
    "# proj_nd_shifted = loop_lsqf(h5_f)\n",
    "# proj_nd_shifted_transposed = np.transpose(proj_nd_shifted,(1,0,2,3))\n",
    "\n",
    "# getting parameters for the hysteresis loops\n",
    "params = np.array(h5_f['params_hysteresis'][:])\n",
    "params_names = ['a_0', 'a_1', 'a_2', 'a_3', 'a_4', 'b_0', 'b_1', 'b_2', 'b_3']\n",
    "\n",
    "# voltage vector\n",
    "V = np.swapaxes(np.atleast_2d(h5_f['Measurement_000']['Channel_000']['UDVS'][::2][:, 1][24:120]), 0, 1).astype(np.float64)\n",
    "\n",
    "# to set up a type of loop_fitting function to use. Possible options: ['9 parameters', '13 parameters']\n",
    "func_type = '9 parameters'\n",
    "\n",
    "# retrieve results\n",
    "real_loops = np.array(h5_f['real_loops_hysteresis'][:])\n",
    "unscaled_param_trust = np.array(h5_f['predictions_hysteresis_trustregcg'][:])\n",
    "unscaled_param_adam = np.array(h5_f['predictions_hysteresis_adam'][:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alibek",
   "language": "python",
   "name": "alibek"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c58f42fd11d8ae4df132d3c425059695e86ccc63a852aa66615442730ca8b1fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
